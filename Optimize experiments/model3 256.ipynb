{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\MFEG\\\\dataprocessing\\\\cinc2017denoise.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Concatenate\n",
    "\n",
    "def ince_block(inputs, filters, strides=1):\n",
    "    x1 = Conv1D(filters, 3, strides=strides, padding='same')(inputs)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv1D(filters, 5, strides=1, padding='same')(inputs)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = Conv1D(filters, 9, strides=1, padding='same')(inputs)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    x4 = Conv1D(filters, 17, strides=1, padding='same')(inputs)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Activation('relu')(x4)\n",
    "\n",
    "    x = Concatenate()([x1, x2, x3, x4])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Reshape, Dense, Multiply\n",
    "def se_block(input_tensor, reduction_ratio=16):\n",
    "  channels = input_tensor.shape[-1]\n",
    "  x = GlobalAveragePooling1D()(input_tensor)\n",
    "  x = Reshape((1, channels))(x)\n",
    "  x = Dense(channels // reduction_ratio, activation='relu', use_bias=False)(x)\n",
    "  x = Dense(channels, activation='sigmoid', use_bias=False)(x)\n",
    "  x = Multiply()([input_tensor, x])\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, Dense, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def residual_shrinkage_block_1d(incoming, nb_blocks, out_channels, downsample=False, downsample_strides=2, activation='relu', kernel_size=31,batch_norm=True, bias=True, weights_init='variance_scaling', bias_init='zeros', regularizer='l2', weight_decay=0.0001, trainable=True, name=\"ResidualShrinkageBlock\"):\n",
    "  residual = incoming\n",
    "  in_channels = incoming.shape[-1]\n",
    "  for i in range(nb_blocks):\n",
    "    identity = residual\n",
    "    if downsample:\n",
    "      downsample_strides = 2\n",
    "    else:\n",
    "      downsample_strides = 1\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    # Thresholding\n",
    "    abs_mean = tf.reduce_mean(tf.abs(residual), axis=1, keepdims=True)\n",
    "    scales = Dense(out_channels // 4, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(abs_mean)\n",
    "    scales = BatchNormalization()(scales)\n",
    "    scales = Activation('relu')(scales)\n",
    "    scales = Dense(out_channels, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(scales)\n",
    "    scales = tf.sigmoid(scales)\n",
    "    thres = abs_mean * scales\n",
    "    residual = tf.sign(residual) * tf.maximum(tf.abs(residual) - thres, 0)\n",
    "    \n",
    "    # Downsampling and projection\n",
    "    if downsample_strides > 1:\n",
    "      identity = Conv1D(out_channels, 1, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    if in_channels != out_channels or downsample:\n",
    "      identity = Conv1D(out_channels, 1, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    residual = residual + identity\n",
    "\n",
    "  return residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add\n",
    "\n",
    "def res_block31_dilated_causal(inputs, filters, kernel_size=31, dilation_rate=2,strides=1):\n",
    "  shortcut = inputs\n",
    "  # 使用扩张卷积和因果卷积\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  \n",
    "  # 调整shortcut路径以匹配主路径的维度\n",
    "  if inputs.shape[-1] != filters:\n",
    "    shortcut = Conv1D(filters, 1, strides=strides, padding='causal')(inputs)  \n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "  \n",
    "  x = Add()([x, shortcut])\n",
    "  x = Activation('relu')(x)\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block31(inputs, filters, kernel_size=31, strides=1):\n",
    "    shortcut = inputs\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resxnet(num_classes=4):\n",
    "    input_1 = Input(shape=(4500,1))\n",
    "    x = Conv1D(64, 12, strides=2, padding='same')(input_1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ince_block(x,64)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, out_channels=64, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 32,31,2,1)\n",
    "    x = se_block(x,32)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, kernel_size=16,out_channels=32, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 64,16,2,1)\n",
    "    x = se_block(x,64)\n",
    "    x = res_block31(x, 128, kernel_size=9,strides=2)\n",
    "    x = res_block31(x, 256, kernel_size=6,strides=2)\n",
    "    x = res_block31(x, 512, kernel_size=3,strides=2)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(256, return_sequences=False)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=input_1, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4500, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 2250, 64)     832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2250, 64)     256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2250, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2250, 64)     12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2250, 64)     20544       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2250, 64)     36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2250, 64)     69696       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2250, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2250, 64)     256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2250, 64)     256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2250, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2250, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2250, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2250, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2250, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2250, 256)    0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2250, 256)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2250, 256)    1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2250, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1125, 64)     49216       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1125, 64)     256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1125, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1125, 64)     12352       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs (TFOpLambda)        (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 1, 64)        0           tf.math.abs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 16)        1040        tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 16)        64          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 16)        0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 64)        1088        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 1, 64)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_1 (TFOpLambda)      (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 1, 64)        0           tf.math.reduce_mean[0][0]        \n",
      "                                                                 tf.math.sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 1125, 64)     0           tf.math.abs_1[0][0]              \n",
      "                                                                 tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign (TFOpLambda)       (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum (TFOpLambda)    (None, 1125, 64)     0           tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1125, 64)     16448       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 1125, 64)     0           tf.math.sign[0][0]               \n",
      "                                                                 tf.math.maximum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1125, 64)     4160        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 1125, 64)     0           tf.math.multiply_1[0][0]         \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1125, 32)     63520       tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1125, 32)     128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1125, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1125, 32)     31776       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1125, 32)     2080        tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1125, 32)     128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1125, 32)     128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1125, 32)     0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1125, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 32)           0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 32)        0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1)         32          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 32)        32          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1125, 32)     0           activation_10[0][0]              \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1125, 32)     128         multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1125, 32)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 563, 32)      3104        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 563, 32)      128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 563, 32)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 563, 32)      3104        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_2 (TFOpLambda)      (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 1, 32)        0           tf.math.abs_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 8)         264         tf.math.reduce_mean_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 8)         32          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1, 8)         0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 32)        288         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_1 (TFOpLambda)  (None, 1, 32)        0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_3 (TFOpLambda)      (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 1, 32)        0           tf.math.reduce_mean_1[0][0]      \n",
      "                                                                 tf.math.sigmoid_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 563, 32)      0           tf.math.abs_3[0][0]              \n",
      "                                                                 tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign_1 (TFOpLambda)     (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum_1 (TFOpLambda)  (None, 563, 32)      0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 563, 32)      1056        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 563, 32)      0           tf.math.sign_1[0][0]             \n",
      "                                                                 tf.math.maximum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 563, 32)      1056        conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 563, 32)      0           tf.math.multiply_3[0][0]         \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 563, 64)      4160        tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 563, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 563, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 563, 64)      8256        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 563, 64)      2112        tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 563, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 563, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 563, 64)      0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 563, 64)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1)         64          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 64)        64          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 563, 64)      0           activation_15[0][0]              \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 282, 128)     254080      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 282, 128)     512         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 282, 128)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 282, 128)     508032      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 282, 128)     8320        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 282, 128)     512         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 282, 128)     512         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 282, 128)     0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 282, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 141, 256)     1016064     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 141, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 141, 256)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 141, 256)     2031872     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 141, 256)     33024       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 141, 256)     1024        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 141, 256)     1024        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 141, 256)     0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 141, 256)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 71, 512)      4063744     activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 71, 512)      2048        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 71, 512)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 71, 512)      8126976     activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 71, 512)      131584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 71, 512)      2048        conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 71, 512)      2048        conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 71, 512)      0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 71, 512)      0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 71, 512)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 256)          591360      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            1028        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,126,524\n",
      "Trainable params: 17,119,116\n",
      "Non-trainable params: 7,408\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      " 6/55 [==>...........................] - ETA: 15s - loss: 5.3223 - accuracy: 0.4792WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1293s vs `on_train_batch_end` time: 0.1546s). Check your callbacks.\n",
      "55/55 [==============================] - 52s 499ms/step - loss: 3.7671 - accuracy: 0.5854 - val_loss: 2.5257 - val_accuracy: 0.5760\n",
      "Epoch 2/80\n",
      "55/55 [==============================] - 18s 328ms/step - loss: 1.8644 - accuracy: 0.6973 - val_loss: 1.6790 - val_accuracy: 0.5837\n",
      "Epoch 3/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 1.1369 - accuracy: 0.7522 - val_loss: 1.3177 - val_accuracy: 0.5755\n",
      "Epoch 4/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.7828 - accuracy: 0.7767 - val_loss: 1.1272 - val_accuracy: 0.5755\n",
      "Epoch 5/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.5846 - accuracy: 0.7972 - val_loss: 0.8707 - val_accuracy: 0.5777\n",
      "Epoch 6/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.4618 - accuracy: 0.8103 - val_loss: 0.7302 - val_accuracy: 0.5787\n",
      "Epoch 7/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.3794 - accuracy: 0.8200 - val_loss: 0.6223 - val_accuracy: 0.6142\n",
      "Epoch 8/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.3233 - accuracy: 0.8302 - val_loss: 0.5131 - val_accuracy: 0.6638\n",
      "Epoch 9/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.2912 - accuracy: 0.8334 - val_loss: 0.3413 - val_accuracy: 0.7695\n",
      "Epoch 10/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.2625 - accuracy: 0.8397 - val_loss: 0.4011 - val_accuracy: 0.7117\n",
      "Epoch 11/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.2449 - accuracy: 0.8423 - val_loss: 0.2880 - val_accuracy: 0.7918\n",
      "Epoch 12/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.2346 - accuracy: 0.8455 - val_loss: 0.2512 - val_accuracy: 0.8300\n",
      "Epoch 13/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.2156 - accuracy: 0.8560 - val_loss: 0.2582 - val_accuracy: 0.8174\n",
      "Epoch 14/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.2069 - accuracy: 0.8594 - val_loss: 0.2926 - val_accuracy: 0.7597\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 15/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1883 - accuracy: 0.8740 - val_loss: 0.2061 - val_accuracy: 0.8567\n",
      "Epoch 16/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1699 - accuracy: 0.8873 - val_loss: 0.2193 - val_accuracy: 0.8360\n",
      "Epoch 17/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1622 - accuracy: 0.8933 - val_loss: 0.2183 - val_accuracy: 0.8387\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 18/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1541 - accuracy: 0.9000 - val_loss: 0.1997 - val_accuracy: 0.8583\n",
      "Epoch 19/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1509 - accuracy: 0.9037 - val_loss: 0.1904 - val_accuracy: 0.8747\n",
      "Epoch 20/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1501 - accuracy: 0.9052 - val_loss: 0.1867 - val_accuracy: 0.8757\n",
      "Epoch 21/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1497 - accuracy: 0.9040 - val_loss: 0.1847 - val_accuracy: 0.8774\n",
      "Epoch 22/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1489 - accuracy: 0.9039 - val_loss: 0.1835 - val_accuracy: 0.8790\n",
      "Epoch 23/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1475 - accuracy: 0.9069 - val_loss: 0.1822 - val_accuracy: 0.8768\n",
      "Epoch 24/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1474 - accuracy: 0.9067 - val_loss: 0.1820 - val_accuracy: 0.8790\n",
      "Epoch 25/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1456 - accuracy: 0.9085 - val_loss: 0.1812 - val_accuracy: 0.8812\n",
      "Epoch 26/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1438 - accuracy: 0.9094 - val_loss: 0.1815 - val_accuracy: 0.8779\n",
      "Epoch 27/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1438 - accuracy: 0.9095 - val_loss: 0.1810 - val_accuracy: 0.8801\n",
      "Epoch 28/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1426 - accuracy: 0.9097 - val_loss: 0.1806 - val_accuracy: 0.8812\n",
      "Epoch 29/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1425 - accuracy: 0.9105 - val_loss: 0.1805 - val_accuracy: 0.8817\n",
      "Epoch 30/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1414 - accuracy: 0.9108 - val_loss: 0.1803 - val_accuracy: 0.8801\n",
      "Epoch 31/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1398 - accuracy: 0.9119 - val_loss: 0.1797 - val_accuracy: 0.8812\n",
      "Epoch 32/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1389 - accuracy: 0.9129 - val_loss: 0.1799 - val_accuracy: 0.8807\n",
      "Epoch 33/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1379 - accuracy: 0.9123 - val_loss: 0.1794 - val_accuracy: 0.8823\n",
      "Epoch 34/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1371 - accuracy: 0.9139 - val_loss: 0.1801 - val_accuracy: 0.8834\n",
      "Epoch 35/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1363 - accuracy: 0.9133 - val_loss: 0.1792 - val_accuracy: 0.8834\n",
      "Epoch 36/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1351 - accuracy: 0.9163 - val_loss: 0.1790 - val_accuracy: 0.8823\n",
      "Epoch 37/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1341 - accuracy: 0.9164 - val_loss: 0.1785 - val_accuracy: 0.8845\n",
      "Epoch 38/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1341 - accuracy: 0.9159 - val_loss: 0.1788 - val_accuracy: 0.8834\n",
      "Epoch 39/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1332 - accuracy: 0.9171 - val_loss: 0.1788 - val_accuracy: 0.8861\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 40/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1309 - accuracy: 0.9197 - val_loss: 0.1784 - val_accuracy: 0.8856\n",
      "Epoch 41/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1301 - accuracy: 0.9203 - val_loss: 0.1782 - val_accuracy: 0.8872\n",
      "Epoch 42/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1304 - accuracy: 0.9197 - val_loss: 0.1781 - val_accuracy: 0.8845\n",
      "Epoch 43/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1306 - accuracy: 0.9196 - val_loss: 0.1780 - val_accuracy: 0.8856\n",
      "Epoch 44/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1310 - accuracy: 0.9194 - val_loss: 0.1780 - val_accuracy: 0.8872\n",
      "Epoch 45/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1303 - accuracy: 0.9192 - val_loss: 0.1780 - val_accuracy: 0.8872\n",
      "Epoch 46/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1308 - accuracy: 0.9191 - val_loss: 0.1780 - val_accuracy: 0.8872\n",
      "Epoch 47/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1298 - accuracy: 0.9197 - val_loss: 0.1780 - val_accuracy: 0.8872\n",
      "Epoch 48/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1300 - accuracy: 0.9198 - val_loss: 0.1779 - val_accuracy: 0.8872\n",
      "Epoch 49/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1304 - accuracy: 0.9205 - val_loss: 0.1779 - val_accuracy: 0.8866\n",
      "Epoch 50/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1298 - accuracy: 0.9206 - val_loss: 0.1779 - val_accuracy: 0.8861\n",
      "Epoch 51/80\n",
      "55/55 [==============================] - 18s 333ms/step - loss: 0.1302 - accuracy: 0.9190 - val_loss: 0.1779 - val_accuracy: 0.8872\n",
      "Epoch 52/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1295 - accuracy: 0.9205 - val_loss: 0.1780 - val_accuracy: 0.8866\n",
      "Epoch 53/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1302 - accuracy: 0.9196 - val_loss: 0.1779 - val_accuracy: 0.8866\n",
      "Reduced learning rate to 1.0000001537946446e-07.\n",
      "Epoch 54/80\n",
      "55/55 [==============================] - 18s 332ms/step - loss: 0.1289 - accuracy: 0.9222 - val_loss: 0.1779 - val_accuracy: 0.8866\n"
     ]
    }
   ],
   "source": [
    "model = resxnet()\n",
    "model.summary()\n",
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=256, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8137940387870912\n",
      "Recall: 0.821487402160324\n",
      "F1 Score: 0.8149575322213505\n",
      "Accuracy: 0.8728881737731295\n",
      "Class 1 - Precision: 0.8076923076923077, Recall: 0.9251101321585903, F1 Score: 0.8624229979466119\n",
      "Class 2 - Precision: 0.8928796471329553, Recall: 0.944037308461026, F1 Score: 0.9177461139896373\n",
      "Class 3 - Precision: 0.8546042003231018, Recall: 0.7168021680216802, F1 Score: 0.7796610169491526\n",
      "Class 4 - Precision: 0.7, Recall: 0.7, F1 Score: 0.7\n",
      "Class 1 Accuracy: 0.9730490748189863\n",
      "Class 2 Accuracy: 0.8978278358809332\n",
      "Class 3 Accuracy: 0.8797264682220435\n",
      "Class 4 Accuracy: 0.995172968624296\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix2(y_test_classes, y_pred_classes, classes=['A', 'N', 'O', '~'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
