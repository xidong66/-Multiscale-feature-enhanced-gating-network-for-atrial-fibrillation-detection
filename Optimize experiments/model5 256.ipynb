{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\MFEG\\\\dataprocessing\\\\cinc2017denoise.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Concatenate\n",
    "\n",
    "def ince_block(inputs, filters, strides=1):\n",
    "    x1 = Conv1D(filters, 3, strides=strides, padding='same')(inputs)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv1D(filters, 5, strides=1, padding='same')(inputs)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = Conv1D(filters, 9, strides=1, padding='same')(inputs)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    x4 = Conv1D(filters, 17, strides=1, padding='same')(inputs)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Activation('relu')(x4)\n",
    "\n",
    "    x = Concatenate()([x1, x2, x3, x4])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Reshape, Dense, Multiply\n",
    "def se_block(input_tensor, reduction_ratio=16):\n",
    "  channels = input_tensor.shape[-1]\n",
    "  x = GlobalAveragePooling1D()(input_tensor)\n",
    "  x = Reshape((1, channels))(x)\n",
    "  x = Dense(channels // reduction_ratio, activation='relu', use_bias=False)(x)\n",
    "  x = Dense(channels, activation='sigmoid', use_bias=False)(x)\n",
    "  x = Multiply()([input_tensor, x])\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, Dense, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def residual_shrinkage_block_1d(incoming, nb_blocks, out_channels, downsample=False, downsample_strides=2, activation='relu', kernel_size=31,batch_norm=True, bias=True, weights_init='variance_scaling', bias_init='zeros', regularizer='l2', weight_decay=0.0001, trainable=True, name=\"ResidualShrinkageBlock\"):\n",
    "  residual = incoming\n",
    "  in_channels = incoming.shape[-1]\n",
    "  for i in range(nb_blocks):\n",
    "    identity = residual\n",
    "    if downsample:\n",
    "      downsample_strides = 2\n",
    "    else:\n",
    "      downsample_strides = 1\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    # Thresholding\n",
    "    abs_mean = tf.reduce_mean(tf.abs(residual), axis=1, keepdims=True)\n",
    "    scales = Dense(out_channels // 4, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(abs_mean)\n",
    "    scales = BatchNormalization()(scales)\n",
    "    scales = Activation('relu')(scales)\n",
    "    scales = Dense(out_channels, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(scales)\n",
    "    scales = tf.sigmoid(scales)\n",
    "    thres = abs_mean * scales\n",
    "    residual = tf.sign(residual) * tf.maximum(tf.abs(residual) - thres, 0)\n",
    "    \n",
    "    # Downsampling and projection\n",
    "    if downsample_strides > 1:\n",
    "      identity = Conv1D(out_channels, 1, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    if in_channels != out_channels or downsample:\n",
    "      identity = Conv1D(out_channels, 1, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    residual = residual + identity\n",
    "\n",
    "  return residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add\n",
    "\n",
    "def res_block31_dilated_causal(inputs, filters, kernel_size=31, dilation_rate=2,strides=1):\n",
    "  shortcut = inputs\n",
    "  # 使用扩张卷积和因果卷积\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  \n",
    "  # 调整shortcut路径以匹配主路径的维度\n",
    "  if inputs.shape[-1] != filters:\n",
    "    shortcut = Conv1D(filters, 1, strides=strides, padding='causal')(inputs)  \n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "  \n",
    "  x = Add()([x, shortcut])\n",
    "  x = Activation('relu')(x)\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block31(inputs, filters, kernel_size=31, strides=1):\n",
    "    shortcut = inputs\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resxnet(num_classes=4):\n",
    "    input_1 = Input(shape=(4500,1))\n",
    "    x = Conv1D(64, 12, strides=2, padding='same')(input_1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ince_block(x,64)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, out_channels=64, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 32,31,2,1)\n",
    "    x = se_block(x,32)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, out_channels=32, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 64,2,1)\n",
    "    x = se_block(x,64)\n",
    "    x = res_block31(x, 128, kernel_size=9,strides=2)\n",
    "    x = res_block31(x, 256, kernel_size=6,strides=2)\n",
    "    x = res_block31(x, 512, kernel_size=3,strides=2)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(256, return_sequences=False)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=input_1, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4500, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 2250, 64)     832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2250, 64)     256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2250, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2250, 64)     12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2250, 64)     20544       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2250, 64)     36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2250, 64)     69696       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2250, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2250, 64)     256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2250, 64)     256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2250, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2250, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2250, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2250, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2250, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2250, 256)    0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2250, 256)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2250, 256)    1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2250, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1125, 64)     49216       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1125, 64)     256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1125, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1125, 64)     12352       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs (TFOpLambda)        (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 1, 64)        0           tf.math.abs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 16)        1040        tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 16)        64          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 16)        0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 64)        1088        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 1, 64)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_1 (TFOpLambda)      (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 1, 64)        0           tf.math.reduce_mean[0][0]        \n",
      "                                                                 tf.math.sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 1125, 64)     0           tf.math.abs_1[0][0]              \n",
      "                                                                 tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign (TFOpLambda)       (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum (TFOpLambda)    (None, 1125, 64)     0           tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1125, 64)     16448       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 1125, 64)     0           tf.math.sign[0][0]               \n",
      "                                                                 tf.math.maximum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1125, 64)     4160        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 1125, 64)     0           tf.math.multiply_1[0][0]         \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1125, 32)     63520       tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1125, 32)     128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1125, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1125, 32)     31776       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1125, 32)     2080        tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1125, 32)     128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1125, 32)     128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1125, 32)     0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1125, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 32)           0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 32)        0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1)         32          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 32)        32          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1125, 32)     0           activation_10[0][0]              \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1125, 32)     128         multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1125, 32)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 563, 32)      3104        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 563, 32)      128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 563, 32)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 563, 32)      3104        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_2 (TFOpLambda)      (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 1, 32)        0           tf.math.abs_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 8)         264         tf.math.reduce_mean_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 8)         32          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1, 8)         0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 32)        288         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_1 (TFOpLambda)  (None, 1, 32)        0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_3 (TFOpLambda)      (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 1, 32)        0           tf.math.reduce_mean_1[0][0]      \n",
      "                                                                 tf.math.sigmoid_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 563, 32)      0           tf.math.abs_3[0][0]              \n",
      "                                                                 tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign_1 (TFOpLambda)     (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum_1 (TFOpLambda)  (None, 563, 32)      0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 563, 32)      1056        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 563, 32)      0           tf.math.sign_1[0][0]             \n",
      "                                                                 tf.math.maximum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 563, 32)      1056        conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 563, 32)      0           tf.math.multiply_3[0][0]         \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 563, 64)      4160        tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 563, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 563, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 563, 64)      8256        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 563, 64)      2112        tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 563, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 563, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 563, 64)      0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 563, 64)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1)         64          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 64)        64          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 563, 64)      0           activation_15[0][0]              \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 282, 128)     254080      multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 282, 128)     512         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 282, 128)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 282, 128)     508032      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 282, 128)     8320        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 282, 128)     512         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 282, 128)     512         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 282, 128)     0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 282, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 141, 256)     1016064     activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 141, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 141, 256)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 141, 256)     2031872     activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 141, 256)     33024       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 141, 256)     1024        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 141, 256)     1024        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 141, 256)     0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 141, 256)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 71, 512)      4063744     activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 71, 512)      2048        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 71, 512)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 71, 512)      8126976     activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 71, 512)      131584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 71, 512)      2048        conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 71, 512)      2048        conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 71, 512)      0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 71, 512)      0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 71, 512)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 256)          591360      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            1028        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,126,524\n",
      "Trainable params: 17,119,116\n",
      "Non-trainable params: 7,408\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      " 6/55 [==>...........................] - ETA: 15s - loss: 5.4359 - accuracy: 0.4479WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1272s vs `on_train_batch_end` time: 0.1528s). Check your callbacks.\n",
      "55/55 [==============================] - 52s 492ms/step - loss: 3.8987 - accuracy: 0.5726 - val_loss: 2.6172 - val_accuracy: 0.5553\n",
      "Epoch 2/80\n",
      "55/55 [==============================] - 18s 325ms/step - loss: 1.9525 - accuracy: 0.6618 - val_loss: 1.7741 - val_accuracy: 0.5755\n",
      "Epoch 3/80\n",
      "55/55 [==============================] - 18s 327ms/step - loss: 1.1759 - accuracy: 0.7476 - val_loss: 1.3820 - val_accuracy: 0.5755\n",
      "Epoch 4/80\n",
      "55/55 [==============================] - 18s 327ms/step - loss: 0.7998 - accuracy: 0.7850 - val_loss: 1.2564 - val_accuracy: 0.5755\n",
      "Epoch 5/80\n",
      "55/55 [==============================] - 18s 328ms/step - loss: 0.5893 - accuracy: 0.8096 - val_loss: 1.0206 - val_accuracy: 0.5766\n",
      "Epoch 6/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.4622 - accuracy: 0.8217 - val_loss: 0.8969 - val_accuracy: 0.5766\n",
      "Epoch 7/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.3815 - accuracy: 0.8238 - val_loss: 0.7147 - val_accuracy: 0.5902\n",
      "Epoch 8/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.3287 - accuracy: 0.8309 - val_loss: 0.6352 - val_accuracy: 0.6191\n",
      "Epoch 9/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.2906 - accuracy: 0.8385 - val_loss: 0.3758 - val_accuracy: 0.7493\n",
      "Epoch 10/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.2633 - accuracy: 0.8418 - val_loss: 0.2814 - val_accuracy: 0.8109\n",
      "Epoch 11/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.2465 - accuracy: 0.8430 - val_loss: 0.2635 - val_accuracy: 0.8223\n",
      "Epoch 12/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.2312 - accuracy: 0.8494 - val_loss: 0.2465 - val_accuracy: 0.8185\n",
      "Epoch 13/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.2172 - accuracy: 0.8540 - val_loss: 0.2337 - val_accuracy: 0.8349\n",
      "Epoch 14/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.2107 - accuracy: 0.8587 - val_loss: 0.2521 - val_accuracy: 0.8262\n",
      "Epoch 15/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.2037 - accuracy: 0.8603 - val_loss: 0.2525 - val_accuracy: 0.8213\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 16/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1778 - accuracy: 0.8827 - val_loss: 0.2127 - val_accuracy: 0.8561\n",
      "Epoch 17/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1624 - accuracy: 0.8946 - val_loss: 0.2224 - val_accuracy: 0.8387\n",
      "Epoch 18/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1545 - accuracy: 0.9001 - val_loss: 0.2322 - val_accuracy: 0.8311\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 19/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1458 - accuracy: 0.9082 - val_loss: 0.2059 - val_accuracy: 0.8534\n",
      "Epoch 20/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1442 - accuracy: 0.9090 - val_loss: 0.1945 - val_accuracy: 0.8703\n",
      "Epoch 21/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1425 - accuracy: 0.9095 - val_loss: 0.1899 - val_accuracy: 0.8725\n",
      "Epoch 22/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1431 - accuracy: 0.9089 - val_loss: 0.1878 - val_accuracy: 0.8768\n",
      "Epoch 23/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1415 - accuracy: 0.9106 - val_loss: 0.1862 - val_accuracy: 0.8785\n",
      "Epoch 24/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1393 - accuracy: 0.9131 - val_loss: 0.1858 - val_accuracy: 0.8763\n",
      "Epoch 25/80\n",
      "55/55 [==============================] - 18s 331ms/step - loss: 0.1389 - accuracy: 0.9129 - val_loss: 0.1852 - val_accuracy: 0.8796\n",
      "Epoch 26/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1387 - accuracy: 0.9130 - val_loss: 0.1852 - val_accuracy: 0.8779\n",
      "Epoch 27/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1372 - accuracy: 0.9139 - val_loss: 0.1844 - val_accuracy: 0.8790\n",
      "Epoch 28/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1358 - accuracy: 0.9138 - val_loss: 0.1841 - val_accuracy: 0.8801\n",
      "Epoch 29/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1353 - accuracy: 0.9157 - val_loss: 0.1841 - val_accuracy: 0.8796\n",
      "Epoch 30/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1345 - accuracy: 0.9158 - val_loss: 0.1837 - val_accuracy: 0.8801\n",
      "Epoch 31/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1338 - accuracy: 0.9164 - val_loss: 0.1834 - val_accuracy: 0.8796\n",
      "Epoch 32/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1318 - accuracy: 0.9188 - val_loss: 0.1832 - val_accuracy: 0.8801\n",
      "Epoch 33/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1324 - accuracy: 0.9176 - val_loss: 0.1836 - val_accuracy: 0.8801\n",
      "Epoch 34/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1300 - accuracy: 0.9182 - val_loss: 0.1833 - val_accuracy: 0.8807\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 35/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1286 - accuracy: 0.9193 - val_loss: 0.1826 - val_accuracy: 0.8790\n",
      "Epoch 36/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1289 - accuracy: 0.9198 - val_loss: 0.1824 - val_accuracy: 0.8796\n",
      "Epoch 37/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1286 - accuracy: 0.9211 - val_loss: 0.1824 - val_accuracy: 0.8785\n",
      "Epoch 38/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1293 - accuracy: 0.9196 - val_loss: 0.1824 - val_accuracy: 0.8779\n",
      "Epoch 39/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1279 - accuracy: 0.9208 - val_loss: 0.1824 - val_accuracy: 0.8779\n",
      "Reduced learning rate to 1.0000001537946446e-07.\n",
      "Epoch 40/80\n",
      "55/55 [==============================] - 18s 330ms/step - loss: 0.1293 - accuracy: 0.9193 - val_loss: 0.1824 - val_accuracy: 0.8779\n",
      "Epoch 41/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1287 - accuracy: 0.9201 - val_loss: 0.1824 - val_accuracy: 0.8779\n",
      "Reduced learning rate to 1.000000171558213e-08.\n",
      "Epoch 42/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1286 - accuracy: 0.9205 - val_loss: 0.1824 - val_accuracy: 0.8779\n",
      "Epoch 43/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1274 - accuracy: 0.9226 - val_loss: 0.1824 - val_accuracy: 0.8774\n",
      "Epoch 44/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1282 - accuracy: 0.9200 - val_loss: 0.1824 - val_accuracy: 0.8779\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 45/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1286 - accuracy: 0.9205 - val_loss: 0.1824 - val_accuracy: 0.8779\n",
      "Epoch 46/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1277 - accuracy: 0.9221 - val_loss: 0.1824 - val_accuracy: 0.8779\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 47/80\n",
      "55/55 [==============================] - 18s 329ms/step - loss: 0.1278 - accuracy: 0.9209 - val_loss: 0.1824 - val_accuracy: 0.8779\n"
     ]
    }
   ],
   "source": [
    "model = resxnet()\n",
    "model.summary()\n",
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=256, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.831392779525485\n",
      "Recall: 0.8130714441072012\n",
      "F1 Score: 0.8205449261549336\n",
      "Accuracy: 0.8777152051488335\n",
      "Class 1 - Precision: 0.859504132231405, Recall: 0.9162995594713657, F1 Score: 0.8869936034115139\n",
      "Class 2 - Precision: 0.8935361216730038, Recall: 0.9393737508327782, F1 Score: 0.9158817797986359\n",
      "Class 3 - Precision: 0.8503086419753086, Recall: 0.7466124661246613, F1 Score: 0.7950937950937952\n",
      "Class 4 - Precision: 0.7222222222222222, Recall: 0.65, F1 Score: 0.6842105263157895\n",
      "Class 1 Accuracy: 0.9786806114239742\n",
      "Class 2 Accuracy: 0.8958165728077232\n",
      "Class 3 Accuracy: 0.8857602574416734\n",
      "Class 4 Accuracy: 0.995172968624296\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix2(y_test_classes, y_pred_classes, classes=['A', 'N', 'O', '~'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
