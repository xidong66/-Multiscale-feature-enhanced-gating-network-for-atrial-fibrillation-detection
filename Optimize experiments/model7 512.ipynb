{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\MFEG\\\\dataprocessing\\\\cinc2017denoise.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Concatenate\n",
    "\n",
    "def ince_block(inputs, filters, strides=1):\n",
    "    x1 = Conv1D(filters, 3, strides=strides, padding='same')(inputs)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv1D(filters, 5, strides=1, padding='same')(inputs)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = Conv1D(filters, 9, strides=1, padding='same')(inputs)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    x4 = Conv1D(filters, 17, strides=1, padding='same')(inputs)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Activation('relu')(x4)\n",
    "\n",
    "    x = Concatenate()([x1, x2, x3, x4])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Reshape, Dense, Multiply\n",
    "def se_block(input_tensor, reduction_ratio=16):\n",
    "  channels = input_tensor.shape[-1]\n",
    "  x = GlobalAveragePooling1D()(input_tensor)\n",
    "  x = Reshape((1, channels))(x)\n",
    "  x = Dense(channels // reduction_ratio, activation='relu', use_bias=False)(x)\n",
    "  x = Dense(channels, activation='sigmoid', use_bias=False)(x)\n",
    "  x = Multiply()([input_tensor, x])\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, Dense, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def residual_shrinkage_block_1d(incoming, nb_blocks, out_channels, downsample=False, downsample_strides=2, activation='relu', kernel_size=31,batch_norm=True, bias=True, weights_init='variance_scaling', bias_init='zeros', regularizer='l2', weight_decay=0.0001, trainable=True, name=\"ResidualShrinkageBlock\"):\n",
    "  residual = incoming\n",
    "  in_channels = incoming.shape[-1]\n",
    "  for i in range(nb_blocks):\n",
    "    identity = residual\n",
    "    if downsample:\n",
    "      downsample_strides = 2\n",
    "    else:\n",
    "      downsample_strides = 1\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    # Thresholding\n",
    "    abs_mean = tf.reduce_mean(tf.abs(residual), axis=1, keepdims=True)\n",
    "    scales = Dense(out_channels // 4, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(abs_mean)\n",
    "    scales = BatchNormalization()(scales)\n",
    "    scales = Activation('relu')(scales)\n",
    "    scales = Dense(out_channels, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(scales)\n",
    "    scales = tf.sigmoid(scales)\n",
    "    thres = abs_mean * scales\n",
    "    residual = tf.sign(residual) * tf.maximum(tf.abs(residual) - thres, 0)\n",
    "    \n",
    "    # Downsampling and projection\n",
    "    if downsample_strides > 1:\n",
    "      identity = Conv1D(out_channels, 1, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    if in_channels != out_channels or downsample:\n",
    "      identity = Conv1D(out_channels, 1, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    residual = residual + identity\n",
    "\n",
    "  return residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add\n",
    "\n",
    "def res_block31_dilated_causal(inputs, filters, kernel_size=31, dilation_rate=2,strides=1):\n",
    "  shortcut = inputs\n",
    "  # 使用扩张卷积和因果卷积\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  \n",
    "  # 调整shortcut路径以匹配主路径的维度\n",
    "  if inputs.shape[-1] != filters:\n",
    "    shortcut = Conv1D(filters, 1, strides=strides, padding='causal')(inputs)  \n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "  \n",
    "  x = Add()([x, shortcut])\n",
    "  x = Activation('relu')(x)\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block31(inputs, filters, kernel_size=31, strides=1):\n",
    "    shortcut = inputs\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resxnet(num_classes=4):\n",
    "    input_1 = Input(shape=(4500,1))\n",
    "    x = Conv1D(64, 12, strides=2, padding='same')(input_1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ince_block(x,64)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, out_channels=64, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 32,31,2,1)\n",
    "    x = se_block(x,32)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, kernel_size=16,out_channels=32, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 64,16,2,1)\n",
    "    x = se_block(x,64)\n",
    "    x = res_block31(x, 128, kernel_size=9,strides=2)\n",
    "    x = res_block31(x, 256, kernel_size=6,strides=2)\n",
    "    x = res_block31(x, 512, kernel_size=3,strides=2)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(256, return_sequences=False)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=input_1, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4500, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 2250, 64)     832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2250, 64)     256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2250, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2250, 64)     12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2250, 64)     20544       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2250, 64)     36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2250, 64)     69696       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2250, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2250, 64)     256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2250, 64)     256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2250, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2250, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2250, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2250, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2250, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2250, 256)    0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2250, 256)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2250, 256)    1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2250, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1125, 64)     507968      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1125, 64)     256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1125, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1125, 64)     127040      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs (TFOpLambda)        (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 1, 64)        0           tf.math.abs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 16)        1040        tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 16)        64          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 16)        0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 64)        1088        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 1, 64)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_1 (TFOpLambda)      (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 1, 64)        0           tf.math.reduce_mean[0][0]        \n",
      "                                                                 tf.math.sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 1125, 64)     0           tf.math.abs_1[0][0]              \n",
      "                                                                 tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign (TFOpLambda)       (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum (TFOpLambda)    (None, 1125, 64)     0           tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1125, 64)     16448       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 1125, 64)     0           tf.math.sign[0][0]               \n",
      "                                                                 tf.math.maximum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1125, 64)     4160        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 1125, 64)     0           tf.math.multiply_1[0][0]         \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1125, 32)     63520       tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1125, 32)     128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1125, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1125, 32)     31776       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1125, 32)     2080        tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1125, 32)     128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1125, 32)     128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1125, 32)     0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1125, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 32)           0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 32)        0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1)         32          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 32)        32          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1125, 32)     0           activation_10[0][0]              \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1125, 32)     128         multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1125, 32)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 563, 32)      16416       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 563, 32)      128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 563, 32)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 563, 32)      16416       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_2 (TFOpLambda)      (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 1, 32)        0           tf.math.abs_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 8)         264         tf.math.reduce_mean_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 8)         32          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1, 8)         0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 32)        288         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_1 (TFOpLambda)  (None, 1, 32)        0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_3 (TFOpLambda)      (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 1, 32)        0           tf.math.reduce_mean_1[0][0]      \n",
      "                                                                 tf.math.sigmoid_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 563, 32)      0           tf.math.abs_3[0][0]              \n",
      "                                                                 tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign_1 (TFOpLambda)     (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum_1 (TFOpLambda)  (None, 563, 32)      0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 563, 32)      1056        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 563, 32)      0           tf.math.sign_1[0][0]             \n",
      "                                                                 tf.math.maximum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 563, 32)      1056        conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 563, 32)      0           tf.math.multiply_3[0][0]         \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 563, 64)      32832       tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 563, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 563, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 563, 64)      65600       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 563, 64)      2112        tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 563, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 563, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 563, 64)      0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 563, 64)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1)         64          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 64)        64          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 563, 64)      0           activation_15[0][0]              \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 282, 128)     73856       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 282, 128)     512         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 282, 128)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 282, 128)     147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 282, 128)     8320        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 282, 128)     512         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 282, 128)     512         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 282, 128)     0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 282, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 141, 256)     196864      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 141, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 141, 256)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 141, 256)     393472      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 141, 256)     33024       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 141, 256)     1024        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 141, 256)     1024        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 141, 256)     0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 141, 256)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 71, 512)      393728      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 71, 512)      2048        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 71, 512)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 71, 512)      786944      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 71, 512)      131584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 71, 512)      2048        conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 71, 512)      2048        conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 71, 512)      0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 71, 512)      0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 71, 512)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 256)          591360      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            1028        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,804,284\n",
      "Trainable params: 3,796,876\n",
      "Non-trainable params: 7,408\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      " 6/28 [=====>........................] - ETA: 14s - loss: 5.3869 - accuracy: 0.4945WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2318s vs `on_train_batch_end` time: 0.3654s). Check your callbacks.\n",
      "28/28 [==============================] - 58s 1s/step - loss: 4.3469 - accuracy: 0.5717 - val_loss: 3.1959 - val_accuracy: 0.5755\n",
      "Epoch 2/80\n",
      "28/28 [==============================] - 19s 684ms/step - loss: 2.5986 - accuracy: 0.6579 - val_loss: 2.2363 - val_accuracy: 0.6071\n",
      "Epoch 3/80\n",
      "28/28 [==============================] - 19s 687ms/step - loss: 1.8579 - accuracy: 0.7472 - val_loss: 1.7059 - val_accuracy: 0.6267\n",
      "Epoch 4/80\n",
      "28/28 [==============================] - 19s 689ms/step - loss: 1.4399 - accuracy: 0.7796 - val_loss: 1.4441 - val_accuracy: 0.5362\n",
      "Epoch 5/80\n",
      "28/28 [==============================] - 19s 690ms/step - loss: 1.1652 - accuracy: 0.7986 - val_loss: 1.3645 - val_accuracy: 0.3471\n",
      "Epoch 6/80\n",
      "28/28 [==============================] - 19s 691ms/step - loss: 0.9674 - accuracy: 0.8098 - val_loss: 1.1429 - val_accuracy: 0.4856\n",
      "Epoch 7/80\n",
      "28/28 [==============================] - 19s 692ms/step - loss: 0.8122 - accuracy: 0.8214 - val_loss: 1.0460 - val_accuracy: 0.5221\n",
      "Epoch 8/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.7015 - accuracy: 0.8234 - val_loss: 0.7460 - val_accuracy: 0.7221\n",
      "Epoch 9/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.6144 - accuracy: 0.8259 - val_loss: 0.6720 - val_accuracy: 0.7090\n",
      "Epoch 10/80\n",
      "28/28 [==============================] - 19s 695ms/step - loss: 0.5344 - accuracy: 0.8359 - val_loss: 0.6917 - val_accuracy: 0.5215\n",
      "Epoch 11/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.4819 - accuracy: 0.8350 - val_loss: 0.5322 - val_accuracy: 0.7700\n",
      "Epoch 12/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.4366 - accuracy: 0.8361 - val_loss: 0.4814 - val_accuracy: 0.7837\n",
      "Epoch 13/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.3936 - accuracy: 0.8418 - val_loss: 0.4809 - val_accuracy: 0.7046\n",
      "Epoch 14/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.3677 - accuracy: 0.8430 - val_loss: 0.4579 - val_accuracy: 0.6856\n",
      "Epoch 15/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.3379 - accuracy: 0.8487 - val_loss: 0.3644 - val_accuracy: 0.8087\n",
      "Epoch 16/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.3193 - accuracy: 0.8471 - val_loss: 0.3424 - val_accuracy: 0.8158\n",
      "Epoch 17/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.3021 - accuracy: 0.8471 - val_loss: 0.3190 - val_accuracy: 0.8322\n",
      "Epoch 18/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.2854 - accuracy: 0.8519 - val_loss: 0.3083 - val_accuracy: 0.8180\n",
      "Epoch 19/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.2690 - accuracy: 0.8553 - val_loss: 0.2832 - val_accuracy: 0.8458\n",
      "Epoch 20/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.2515 - accuracy: 0.8635 - val_loss: 0.2942 - val_accuracy: 0.8202\n",
      "Epoch 21/80\n",
      "28/28 [==============================] - 19s 695ms/step - loss: 0.2454 - accuracy: 0.8622 - val_loss: 0.3047 - val_accuracy: 0.8136\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 22/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.2187 - accuracy: 0.8826 - val_loss: 0.2500 - val_accuracy: 0.8425\n",
      "Epoch 23/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.2015 - accuracy: 0.8917 - val_loss: 0.2873 - val_accuracy: 0.8120\n",
      "Epoch 24/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1908 - accuracy: 0.8997 - val_loss: 0.3356 - val_accuracy: 0.7706\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 25/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1812 - accuracy: 0.9061 - val_loss: 0.3027 - val_accuracy: 0.7978\n",
      "Epoch 26/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1786 - accuracy: 0.9097 - val_loss: 0.2866 - val_accuracy: 0.8109\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 27/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1763 - accuracy: 0.9112 - val_loss: 0.2595 - val_accuracy: 0.8338\n",
      "Epoch 28/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1770 - accuracy: 0.9107 - val_loss: 0.2417 - val_accuracy: 0.8490\n",
      "Epoch 29/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1760 - accuracy: 0.9121 - val_loss: 0.2301 - val_accuracy: 0.8572\n",
      "Epoch 30/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1762 - accuracy: 0.9119 - val_loss: 0.2224 - val_accuracy: 0.8638\n",
      "Epoch 31/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1757 - accuracy: 0.9117 - val_loss: 0.2177 - val_accuracy: 0.8714\n",
      "Epoch 32/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1762 - accuracy: 0.9112 - val_loss: 0.2148 - val_accuracy: 0.8747\n",
      "Epoch 33/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1754 - accuracy: 0.9124 - val_loss: 0.2128 - val_accuracy: 0.8779\n",
      "Epoch 34/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1757 - accuracy: 0.9121 - val_loss: 0.2117 - val_accuracy: 0.8785\n",
      "Epoch 35/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1756 - accuracy: 0.9127 - val_loss: 0.2109 - val_accuracy: 0.8785\n",
      "Epoch 36/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1754 - accuracy: 0.9132 - val_loss: 0.2105 - val_accuracy: 0.8796\n",
      "Epoch 37/80\n",
      "28/28 [==============================] - 19s 695ms/step - loss: 0.1748 - accuracy: 0.9127 - val_loss: 0.2102 - val_accuracy: 0.8801\n",
      "Epoch 38/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1750 - accuracy: 0.9125 - val_loss: 0.2100 - val_accuracy: 0.8807\n",
      "Epoch 39/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1743 - accuracy: 0.9131 - val_loss: 0.2099 - val_accuracy: 0.8828\n",
      "Epoch 40/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1748 - accuracy: 0.9122 - val_loss: 0.2097 - val_accuracy: 0.8823\n",
      "Epoch 41/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1741 - accuracy: 0.9136 - val_loss: 0.2096 - val_accuracy: 0.8817\n",
      "Epoch 42/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1743 - accuracy: 0.9129 - val_loss: 0.2096 - val_accuracy: 0.8812\n",
      "Epoch 43/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1741 - accuracy: 0.9131 - val_loss: 0.2095 - val_accuracy: 0.8812\n",
      "Epoch 44/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1742 - accuracy: 0.9124 - val_loss: 0.2094 - val_accuracy: 0.8817\n",
      "Epoch 45/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1736 - accuracy: 0.9125 - val_loss: 0.2093 - val_accuracy: 0.8807\n",
      "Epoch 46/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1729 - accuracy: 0.9144 - val_loss: 0.2093 - val_accuracy: 0.8807\n",
      "Epoch 47/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1735 - accuracy: 0.9130 - val_loss: 0.2092 - val_accuracy: 0.8812\n",
      "Epoch 48/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1732 - accuracy: 0.9141 - val_loss: 0.2092 - val_accuracy: 0.8807\n",
      "Epoch 49/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1732 - accuracy: 0.9142 - val_loss: 0.2090 - val_accuracy: 0.8807\n",
      "Epoch 50/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1734 - accuracy: 0.9138 - val_loss: 0.2089 - val_accuracy: 0.8801\n",
      "Epoch 51/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1730 - accuracy: 0.9144 - val_loss: 0.2090 - val_accuracy: 0.8796\n",
      "Epoch 52/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1730 - accuracy: 0.9141 - val_loss: 0.2089 - val_accuracy: 0.8801\n",
      "Reduced learning rate to 1.0000001537946446e-07.\n",
      "Epoch 53/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1723 - accuracy: 0.9134 - val_loss: 0.2089 - val_accuracy: 0.8801\n",
      "Epoch 54/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1722 - accuracy: 0.9140 - val_loss: 0.2089 - val_accuracy: 0.8796\n",
      "Epoch 55/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1727 - accuracy: 0.9143 - val_loss: 0.2089 - val_accuracy: 0.8801\n",
      "Epoch 56/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1730 - accuracy: 0.9144 - val_loss: 0.2089 - val_accuracy: 0.8801\n",
      "Epoch 57/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1722 - accuracy: 0.9146 - val_loss: 0.2089 - val_accuracy: 0.8807\n",
      "Epoch 58/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1723 - accuracy: 0.9141 - val_loss: 0.2089 - val_accuracy: 0.8807\n",
      "Reduced learning rate to 1.000000171558213e-08.\n",
      "Epoch 59/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1725 - accuracy: 0.9141 - val_loss: 0.2089 - val_accuracy: 0.8807\n",
      "Epoch 60/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1731 - accuracy: 0.9138 - val_loss: 0.2089 - val_accuracy: 0.8812\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 61/80\n",
      "28/28 [==============================] - 19s 695ms/step - loss: 0.1725 - accuracy: 0.9145 - val_loss: 0.2089 - val_accuracy: 0.8812\n",
      "Epoch 62/80\n",
      "28/28 [==============================] - 19s 694ms/step - loss: 0.1724 - accuracy: 0.9149 - val_loss: 0.2089 - val_accuracy: 0.8812\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 63/80\n",
      "28/28 [==============================] - 19s 693ms/step - loss: 0.1732 - accuracy: 0.9142 - val_loss: 0.2089 - val_accuracy: 0.8812\n"
     ]
    }
   ],
   "source": [
    "model = resxnet()\n",
    "model.summary()\n",
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=512, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8349934372297064\n",
      "Recall: 0.8218225883308354\n",
      "F1 Score: 0.826616472982229\n",
      "Accuracy: 0.8753016894609815\n",
      "Class 1 - Precision: 0.8630705394190872, Recall: 0.9162995594713657, F1 Score: 0.888888888888889\n",
      "Class 2 - Precision: 0.8879148403256105, Recall: 0.9447035309793471, F1 Score: 0.9154293092317626\n",
      "Class 3 - Precision: 0.8521462639109698, Recall: 0.7262872628726287, F1 Score: 0.7841989758595463\n",
      "Class 4 - Precision: 0.7368421052631579, Recall: 0.7, F1 Score: 0.717948717948718\n",
      "Class 1 Accuracy: 0.9790828640386162\n",
      "Class 2 Accuracy: 0.8946098149637972\n",
      "Class 3 Accuracy: 0.8813354786806115\n",
      "Class 4 Accuracy: 0.995575221238938\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix2(y_test_classes, y_pred_classes, classes=['A', 'N', 'O', '~'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
