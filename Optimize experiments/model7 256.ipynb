{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\MFEG\\\\dataprocessing\\\\cinc2017denoise2.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Concatenate\n",
    "\n",
    "def ince_block(inputs, filters, strides=1):\n",
    "    x1 = Conv1D(filters, 3, strides=strides, padding='same')(inputs)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv1D(filters, 5, strides=1, padding='same')(inputs)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = Conv1D(filters, 9, strides=1, padding='same')(inputs)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    x4 = Conv1D(filters, 17, strides=1, padding='same')(inputs)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Activation('relu')(x4)\n",
    "\n",
    "    x = Concatenate()([x1, x2, x3, x4])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Reshape, Dense, Multiply\n",
    "def se_block(input_tensor, reduction_ratio=16):\n",
    "  channels = input_tensor.shape[-1]\n",
    "  x = GlobalAveragePooling1D()(input_tensor)\n",
    "  x = Reshape((1, channels))(x)\n",
    "  x = Dense(channels // reduction_ratio, activation='relu', use_bias=False)(x)\n",
    "  x = Dense(channels, activation='sigmoid', use_bias=False)(x)\n",
    "  x = Multiply()([input_tensor, x])\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, Dense, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def residual_shrinkage_block_1d(incoming, nb_blocks, out_channels, downsample=False, downsample_strides=2, activation='relu', kernel_size=31,batch_norm=True, bias=True, weights_init='variance_scaling', bias_init='zeros', regularizer='l2', weight_decay=0.0001, trainable=True, name=\"ResidualShrinkageBlock\"):\n",
    "  residual = incoming\n",
    "  in_channels = incoming.shape[-1]\n",
    "  for i in range(nb_blocks):\n",
    "    identity = residual\n",
    "    if downsample:\n",
    "      downsample_strides = 2\n",
    "    else:\n",
    "      downsample_strides = 1\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    # Thresholding\n",
    "    abs_mean = tf.reduce_mean(tf.abs(residual), axis=1, keepdims=True)\n",
    "    scales = Dense(out_channels // 4, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(abs_mean)\n",
    "    scales = BatchNormalization()(scales)\n",
    "    scales = Activation('relu')(scales)\n",
    "    scales = Dense(out_channels, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(scales)\n",
    "    scales = tf.sigmoid(scales)\n",
    "    thres = abs_mean * scales\n",
    "    residual = tf.sign(residual) * tf.maximum(tf.abs(residual) - thres, 0)\n",
    "    \n",
    "    # Downsampling and projection\n",
    "    if downsample_strides > 1:\n",
    "      identity = Conv1D(out_channels, 1, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    if in_channels != out_channels or downsample:\n",
    "      identity = Conv1D(out_channels, 1, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    residual = residual + identity\n",
    "\n",
    "  return residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add\n",
    "\n",
    "def res_block31_dilated_causal(inputs, filters, kernel_size=31, dilation_rate=2,strides=1):\n",
    "  shortcut = inputs\n",
    "  # 使用扩张卷积和因果卷积\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  \n",
    "  # 调整shortcut路径以匹配主路径的维度\n",
    "  if inputs.shape[-1] != filters:\n",
    "    shortcut = Conv1D(filters, 1, strides=strides, padding='causal')(inputs)  \n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "  \n",
    "  x = Add()([x, shortcut])\n",
    "  x = Activation('relu')(x)\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block31(inputs, filters, kernel_size=31, strides=1):\n",
    "    shortcut = inputs\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resxnet(num_classes=4):\n",
    "    input_1 = Input(shape=(4500,1))\n",
    "    x = Conv1D(64, 12, strides=2, padding='same')(input_1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ince_block(x,64)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, out_channels=64, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 32,31,2,1)\n",
    "    x = se_block(x,32)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, kernel_size=16,out_channels=32, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 64,16,2,1)\n",
    "    x = se_block(x,64)\n",
    "    x = res_block31(x, 128, kernel_size=9,strides=2)\n",
    "    x = res_block31(x, 256, kernel_size=6,strides=2)\n",
    "    x = res_block31(x, 512, kernel_size=3,strides=2)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(256, return_sequences=False)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=input_1, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4500, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 2250, 64)     832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2250, 64)     256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2250, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2250, 64)     12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2250, 64)     20544       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2250, 64)     36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2250, 64)     69696       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2250, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2250, 64)     256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2250, 64)     256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2250, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2250, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2250, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2250, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2250, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2250, 256)    0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2250, 256)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2250, 256)    1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2250, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1125, 64)     507968      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1125, 64)     256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1125, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1125, 64)     127040      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs (TFOpLambda)        (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 1, 64)        0           tf.math.abs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 16)        1040        tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 16)        64          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 16)        0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 64)        1088        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 1, 64)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_1 (TFOpLambda)      (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 1, 64)        0           tf.math.reduce_mean[0][0]        \n",
      "                                                                 tf.math.sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 1125, 64)     0           tf.math.abs_1[0][0]              \n",
      "                                                                 tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign (TFOpLambda)       (None, 1125, 64)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum (TFOpLambda)    (None, 1125, 64)     0           tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1125, 64)     16448       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 1125, 64)     0           tf.math.sign[0][0]               \n",
      "                                                                 tf.math.maximum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1125, 64)     4160        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 1125, 64)     0           tf.math.multiply_1[0][0]         \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1125, 32)     63520       tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1125, 32)     128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1125, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1125, 32)     31776       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1125, 32)     2080        tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1125, 32)     128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1125, 32)     128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1125, 32)     0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1125, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 32)           0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 32)        0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1)         32          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 32)        32          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1125, 32)     0           activation_10[0][0]              \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1125, 32)     128         multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1125, 32)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 563, 32)      16416       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 563, 32)      128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 563, 32)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 563, 32)      16416       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_2 (TFOpLambda)      (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 1, 32)        0           tf.math.abs_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 8)         264         tf.math.reduce_mean_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 8)         32          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1, 8)         0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 32)        288         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_1 (TFOpLambda)  (None, 1, 32)        0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_3 (TFOpLambda)      (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 1, 32)        0           tf.math.reduce_mean_1[0][0]      \n",
      "                                                                 tf.math.sigmoid_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 563, 32)      0           tf.math.abs_3[0][0]              \n",
      "                                                                 tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign_1 (TFOpLambda)     (None, 563, 32)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum_1 (TFOpLambda)  (None, 563, 32)      0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 563, 32)      1056        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 563, 32)      0           tf.math.sign_1[0][0]             \n",
      "                                                                 tf.math.maximum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 563, 32)      1056        conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 563, 32)      0           tf.math.multiply_3[0][0]         \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 563, 64)      32832       tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 563, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 563, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 563, 64)      65600       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 563, 64)      2112        tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 563, 64)      256         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 563, 64)      256         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 563, 64)      0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 563, 64)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1)         64          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 64)        64          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 563, 64)      0           activation_15[0][0]              \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 282, 128)     73856       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 282, 128)     512         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 282, 128)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 282, 128)     147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 282, 128)     8320        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 282, 128)     512         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 282, 128)     512         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 282, 128)     0           batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 282, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 141, 256)     196864      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 141, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 141, 256)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 141, 256)     393472      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 141, 256)     33024       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 141, 256)     1024        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 141, 256)     1024        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 141, 256)     0           batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 141, 256)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 71, 512)      393728      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 71, 512)      2048        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 71, 512)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 71, 512)      786944      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 71, 512)      131584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 71, 512)      2048        conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 71, 512)      2048        conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 71, 512)      0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 71, 512)      0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 71, 512)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 256)          591360      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            1028        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,804,284\n",
      "Trainable params: 3,796,876\n",
      "Non-trainable params: 7,408\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      " 6/55 [==>...........................] - ETA: 16s - loss: 5.3883 - accuracy: 0.5260WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1319s vs `on_train_batch_end` time: 0.1679s). Check your callbacks.\n",
      "55/55 [==============================] - 53s 527ms/step - loss: 3.5614 - accuracy: 0.5957 - val_loss: 2.2519 - val_accuracy: 0.6054\n",
      "Epoch 2/80\n",
      "55/55 [==============================] - 19s 349ms/step - loss: 1.6749 - accuracy: 0.7235 - val_loss: 1.3630 - val_accuracy: 0.6518\n",
      "Epoch 3/80\n",
      "55/55 [==============================] - 19s 350ms/step - loss: 1.0814 - accuracy: 0.7707 - val_loss: 1.0613 - val_accuracy: 0.6027\n",
      "Epoch 4/80\n",
      "55/55 [==============================] - 19s 351ms/step - loss: 0.7743 - accuracy: 0.8000 - val_loss: 0.8202 - val_accuracy: 0.6452\n",
      "Epoch 5/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.5926 - accuracy: 0.8094 - val_loss: 0.5905 - val_accuracy: 0.7471\n",
      "Epoch 6/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.4823 - accuracy: 0.8136 - val_loss: 0.4526 - val_accuracy: 0.7918\n",
      "Epoch 7/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.4037 - accuracy: 0.8174 - val_loss: 0.3890 - val_accuracy: 0.8087\n",
      "Epoch 8/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.3569 - accuracy: 0.8213 - val_loss: 0.4338 - val_accuracy: 0.7455\n",
      "Epoch 9/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.3173 - accuracy: 0.8272 - val_loss: 0.3600 - val_accuracy: 0.7804\n",
      "Epoch 10/80\n",
      "55/55 [==============================] - 19s 354ms/step - loss: 0.2992 - accuracy: 0.8276 - val_loss: 0.3078 - val_accuracy: 0.8202\n",
      "Epoch 11/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.2806 - accuracy: 0.8309 - val_loss: 0.3213 - val_accuracy: 0.7896\n",
      "Epoch 12/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.2677 - accuracy: 0.8331 - val_loss: 0.2792 - val_accuracy: 0.8185\n",
      "Epoch 13/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.2524 - accuracy: 0.8372 - val_loss: 0.5139 - val_accuracy: 0.4616\n",
      "Epoch 14/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.2504 - accuracy: 0.8413 - val_loss: 0.2714 - val_accuracy: 0.8207\n",
      "Epoch 15/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.2439 - accuracy: 0.8384 - val_loss: 0.2638 - val_accuracy: 0.8234\n",
      "Epoch 16/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.2406 - accuracy: 0.8392 - val_loss: 0.2818 - val_accuracy: 0.8027\n",
      "Epoch 17/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.2367 - accuracy: 0.8387 - val_loss: 0.2779 - val_accuracy: 0.7995\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 18/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.2097 - accuracy: 0.8645 - val_loss: 0.2347 - val_accuracy: 0.8403\n",
      "Epoch 19/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1910 - accuracy: 0.8726 - val_loss: 0.2359 - val_accuracy: 0.8289\n",
      "Epoch 20/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1831 - accuracy: 0.8776 - val_loss: 0.2338 - val_accuracy: 0.8245\n",
      "Epoch 21/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1789 - accuracy: 0.8770 - val_loss: 0.2276 - val_accuracy: 0.8278\n",
      "Epoch 22/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1735 - accuracy: 0.8811 - val_loss: 0.2355 - val_accuracy: 0.8180\n",
      "Epoch 23/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1713 - accuracy: 0.8812 - val_loss: 0.2316 - val_accuracy: 0.8229\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 24/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1607 - accuracy: 0.8926 - val_loss: 0.2027 - val_accuracy: 0.8583\n",
      "Epoch 25/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1560 - accuracy: 0.8957 - val_loss: 0.1974 - val_accuracy: 0.8605\n",
      "Epoch 26/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1546 - accuracy: 0.8966 - val_loss: 0.1948 - val_accuracy: 0.8599\n",
      "Epoch 27/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1515 - accuracy: 0.9015 - val_loss: 0.1917 - val_accuracy: 0.8621\n",
      "Epoch 28/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1501 - accuracy: 0.9022 - val_loss: 0.1915 - val_accuracy: 0.8605\n",
      "Epoch 29/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1493 - accuracy: 0.9011 - val_loss: 0.1905 - val_accuracy: 0.8638\n",
      "Epoch 30/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1469 - accuracy: 0.9045 - val_loss: 0.1897 - val_accuracy: 0.8616\n",
      "Epoch 31/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1461 - accuracy: 0.9030 - val_loss: 0.1913 - val_accuracy: 0.8610\n",
      "Epoch 32/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1437 - accuracy: 0.9074 - val_loss: 0.1873 - val_accuracy: 0.8665\n",
      "Epoch 33/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1424 - accuracy: 0.9092 - val_loss: 0.1907 - val_accuracy: 0.8643\n",
      "Epoch 34/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1399 - accuracy: 0.9112 - val_loss: 0.1908 - val_accuracy: 0.8632\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 35/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1368 - accuracy: 0.9144 - val_loss: 0.1839 - val_accuracy: 0.8736\n",
      "Epoch 36/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1355 - accuracy: 0.9157 - val_loss: 0.1825 - val_accuracy: 0.8747\n",
      "Epoch 37/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1344 - accuracy: 0.9167 - val_loss: 0.1820 - val_accuracy: 0.8757\n",
      "Epoch 38/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1345 - accuracy: 0.9169 - val_loss: 0.1814 - val_accuracy: 0.8768\n",
      "Epoch 39/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1340 - accuracy: 0.9171 - val_loss: 0.1813 - val_accuracy: 0.8779\n",
      "Epoch 40/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1334 - accuracy: 0.9195 - val_loss: 0.1812 - val_accuracy: 0.8785\n",
      "Epoch 41/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1334 - accuracy: 0.9172 - val_loss: 0.1807 - val_accuracy: 0.8785\n",
      "Epoch 42/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1329 - accuracy: 0.9184 - val_loss: 0.1807 - val_accuracy: 0.8790\n",
      "Epoch 43/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1331 - accuracy: 0.9188 - val_loss: 0.1806 - val_accuracy: 0.8807\n",
      "Epoch 44/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1327 - accuracy: 0.9175 - val_loss: 0.1806 - val_accuracy: 0.8807\n",
      "Epoch 45/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1323 - accuracy: 0.9187 - val_loss: 0.1805 - val_accuracy: 0.8812\n",
      "Epoch 46/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1320 - accuracy: 0.9199 - val_loss: 0.1803 - val_accuracy: 0.8823\n",
      "Epoch 47/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1319 - accuracy: 0.9173 - val_loss: 0.1803 - val_accuracy: 0.8812\n",
      "Epoch 48/80\n",
      "55/55 [==============================] - 19s 354ms/step - loss: 0.1315 - accuracy: 0.9192 - val_loss: 0.1800 - val_accuracy: 0.8807\n",
      "Epoch 49/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1312 - accuracy: 0.9198 - val_loss: 0.1799 - val_accuracy: 0.8807\n",
      "Epoch 50/80\n",
      "55/55 [==============================] - 19s 354ms/step - loss: 0.1312 - accuracy: 0.9201 - val_loss: 0.1799 - val_accuracy: 0.8817\n",
      "Epoch 51/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1304 - accuracy: 0.9200 - val_loss: 0.1802 - val_accuracy: 0.8834\n",
      "Epoch 52/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1301 - accuracy: 0.9222 - val_loss: 0.1797 - val_accuracy: 0.8807\n",
      "Epoch 53/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1293 - accuracy: 0.9221 - val_loss: 0.1796 - val_accuracy: 0.8812\n",
      "Epoch 54/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1299 - accuracy: 0.9197 - val_loss: 0.1797 - val_accuracy: 0.8812\n",
      "Epoch 55/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1293 - accuracy: 0.9211 - val_loss: 0.1794 - val_accuracy: 0.8817\n",
      "Epoch 56/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1294 - accuracy: 0.9205 - val_loss: 0.1798 - val_accuracy: 0.8812\n",
      "Epoch 57/80\n",
      "55/55 [==============================] - 19s 354ms/step - loss: 0.1286 - accuracy: 0.9216 - val_loss: 0.1794 - val_accuracy: 0.8817\n",
      "Epoch 58/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1289 - accuracy: 0.9221 - val_loss: 0.1793 - val_accuracy: 0.8823\n",
      "Epoch 59/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1278 - accuracy: 0.9232 - val_loss: 0.1794 - val_accuracy: 0.8834\n",
      "Epoch 60/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1281 - accuracy: 0.9223 - val_loss: 0.1794 - val_accuracy: 0.8828\n",
      "Reduced learning rate to 1.0000001537946446e-07.\n",
      "Epoch 61/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1274 - accuracy: 0.9241 - val_loss: 0.1793 - val_accuracy: 0.8828\n",
      "Epoch 62/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1277 - accuracy: 0.9231 - val_loss: 0.1793 - val_accuracy: 0.8828\n",
      "Epoch 63/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1271 - accuracy: 0.9231 - val_loss: 0.1793 - val_accuracy: 0.8823\n",
      "Epoch 64/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1267 - accuracy: 0.9240 - val_loss: 0.1793 - val_accuracy: 0.8823\n",
      "Epoch 65/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1271 - accuracy: 0.9233 - val_loss: 0.1793 - val_accuracy: 0.8828\n",
      "Epoch 66/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1273 - accuracy: 0.9234 - val_loss: 0.1793 - val_accuracy: 0.8823\n",
      "Reduced learning rate to 1.000000171558213e-08.\n",
      "Epoch 67/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1272 - accuracy: 0.9240 - val_loss: 0.1793 - val_accuracy: 0.8823\n",
      "Epoch 68/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1268 - accuracy: 0.9239 - val_loss: 0.1793 - val_accuracy: 0.8823\n",
      "Epoch 69/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1276 - accuracy: 0.9224 - val_loss: 0.1793 - val_accuracy: 0.8823\n",
      "Epoch 70/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1276 - accuracy: 0.9226 - val_loss: 0.1793 - val_accuracy: 0.8823\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 71/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1273 - accuracy: 0.9228 - val_loss: 0.1793 - val_accuracy: 0.8823\n",
      "Epoch 72/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1269 - accuracy: 0.9235 - val_loss: 0.1793 - val_accuracy: 0.8823\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 73/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1276 - accuracy: 0.9229 - val_loss: 0.1792 - val_accuracy: 0.8823\n",
      "Epoch 74/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1272 - accuracy: 0.9223 - val_loss: 0.1792 - val_accuracy: 0.8823\n",
      "Epoch 75/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1268 - accuracy: 0.9235 - val_loss: 0.1792 - val_accuracy: 0.8823\n",
      "Epoch 76/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1277 - accuracy: 0.9226 - val_loss: 0.1792 - val_accuracy: 0.8823\n",
      "Epoch 77/80\n",
      "55/55 [==============================] - 19s 352ms/step - loss: 0.1269 - accuracy: 0.9240 - val_loss: 0.1792 - val_accuracy: 0.8823\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 78/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1269 - accuracy: 0.9238 - val_loss: 0.1792 - val_accuracy: 0.8823\n",
      "Epoch 79/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1275 - accuracy: 0.9227 - val_loss: 0.1792 - val_accuracy: 0.8823\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 80/80\n",
      "55/55 [==============================] - 19s 353ms/step - loss: 0.1266 - accuracy: 0.9232 - val_loss: 0.1792 - val_accuracy: 0.8823\n"
     ]
    }
   ],
   "source": [
    "model = resxnet()\n",
    "model.summary()\n",
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=256, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8661521246977878\n",
      "Recall: 0.8339900596773535\n",
      "F1 Score: 0.8477186525843357\n",
      "Accuracy: 0.8801287208366855\n",
      "Class 1 - Precision: 0.8347107438016529, Recall: 0.8898678414096917, F1 Score: 0.861407249466951\n",
      "Class 2 - Precision: 0.9012738853503185, Recall: 0.9427048634243838, F1 Score: 0.9215239335721264\n",
      "Class 3 - Precision: 0.8462709284627092, Recall: 0.7533875338753387, F1 Score: 0.797132616487455\n",
      "Class 4 - Precision: 0.8823529411764706, Recall: 0.75, F1 Score: 0.8108108108108107\n",
      "Class 1 Accuracy: 0.9738535800482703\n",
      "Class 2 Accuracy: 0.9030571198712791\n",
      "Class 3 Accuracy: 0.8861625100563154\n",
      "Class 4 Accuracy: 0.997184231697506\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix2(y_test_classes, y_pred_classes, classes=['A', 'N', 'O', '~'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
