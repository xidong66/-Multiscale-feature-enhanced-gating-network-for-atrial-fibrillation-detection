{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\database\\\\cinc2017denoise.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4500, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 4500, 32)     640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 4500, 32)     128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 4500, 32)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2250, 32)     3104        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2250, 32)     128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2250, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2250, 32)     3104        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2250, 32)     1056        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2250, 32)     128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2250, 32)     128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2250, 32)     0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2250, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1125, 64)     6208        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1125, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1125, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1125, 64)     12352       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1125, 64)     2112        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1125, 64)     256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1125, 64)     256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1125, 64)     0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1125, 64)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 563, 128)     24704       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 563, 128)     512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 563, 128)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 563, 128)     49280       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 563, 128)     8320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 563, 128)     512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 563, 128)     512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 563, 128)     0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 563, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 128)          99072       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 128)          99072       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 128)          0           gru[0][0]                        \n",
      "                                                                 gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            516         tf.__operators__.add[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 312,356\n",
      "Trainable params: 310,948\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dropout, Dense,MaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x, filters, kernel_size, strides):\n",
    "    shortcut = x\n",
    "    # 主卷积路径\n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 如果shortcut的形状与x不匹配，则调整shortcut\n",
    "    if shortcut.shape[-1] != x.shape[-1] or shortcut.shape[-2] != x.shape[-2]:\n",
    "        shortcut = Conv1D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # 添加跳过连接\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def resnet(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(32, 19, strides=1, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = residual_block(x, 32, 3, 2)\n",
    "    x = residual_block(x, 64, 3, 2)\n",
    "    x = residual_block(x, 128, 3, 2)\n",
    "    x1 = GRU(128, return_sequences=False)(x)\n",
    "    x2 = GRU(128, return_sequences=False)(x)\n",
    "    x=x1+x2\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "model =resnet((4500, 1), 4)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "55/55 [==============================] - 31s 335ms/step - loss: 0.4207 - accuracy: 0.5794 - val_loss: 0.4360 - val_accuracy: 0.5760\n",
      "Epoch 2/80\n",
      "55/55 [==============================] - 17s 308ms/step - loss: 0.4028 - accuracy: 0.5942 - val_loss: 0.4113 - val_accuracy: 0.5815\n",
      "Epoch 3/80\n",
      "55/55 [==============================] - 17s 303ms/step - loss: 0.3933 - accuracy: 0.6067 - val_loss: 0.3959 - val_accuracy: 0.6060\n",
      "Epoch 4/80\n",
      "55/55 [==============================] - 17s 302ms/step - loss: 0.3691 - accuracy: 0.6436 - val_loss: 0.3698 - val_accuracy: 0.6381\n",
      "Epoch 5/80\n",
      "55/55 [==============================] - 17s 301ms/step - loss: 0.3367 - accuracy: 0.6777 - val_loss: 0.3393 - val_accuracy: 0.6741\n",
      "Epoch 6/80\n",
      "55/55 [==============================] - 17s 306ms/step - loss: 0.3106 - accuracy: 0.7127 - val_loss: 0.3280 - val_accuracy: 0.6937\n",
      "Epoch 7/80\n",
      "55/55 [==============================] - 17s 306ms/step - loss: 0.2847 - accuracy: 0.7493 - val_loss: 0.2920 - val_accuracy: 0.7450\n",
      "Epoch 8/80\n",
      "55/55 [==============================] - 17s 304ms/step - loss: 0.2658 - accuracy: 0.7708 - val_loss: 0.2711 - val_accuracy: 0.7640\n",
      "Epoch 9/80\n",
      "55/55 [==============================] - 17s 301ms/step - loss: 0.2550 - accuracy: 0.7824 - val_loss: 0.2691 - val_accuracy: 0.7619\n",
      "Epoch 10/80\n",
      "55/55 [==============================] - 17s 303ms/step - loss: 0.2370 - accuracy: 0.7994 - val_loss: 0.2499 - val_accuracy: 0.7880\n",
      "Epoch 11/80\n",
      "55/55 [==============================] - 16s 298ms/step - loss: 0.2228 - accuracy: 0.8172 - val_loss: 0.2360 - val_accuracy: 0.8104\n",
      "Epoch 12/80\n",
      "55/55 [==============================] - 17s 305ms/step - loss: 0.2124 - accuracy: 0.8252 - val_loss: 0.2267 - val_accuracy: 0.8136\n",
      "Epoch 13/80\n",
      "55/55 [==============================] - 17s 302ms/step - loss: 0.2008 - accuracy: 0.8389 - val_loss: 0.2324 - val_accuracy: 0.8169\n",
      "Epoch 14/80\n",
      "55/55 [==============================] - 16s 299ms/step - loss: 0.1940 - accuracy: 0.8465 - val_loss: 0.2097 - val_accuracy: 0.8387\n",
      "Epoch 15/80\n",
      "55/55 [==============================] - 17s 301ms/step - loss: 0.1891 - accuracy: 0.8492 - val_loss: 0.2130 - val_accuracy: 0.8305\n",
      "Epoch 16/80\n",
      "55/55 [==============================] - 17s 302ms/step - loss: 0.1795 - accuracy: 0.8566 - val_loss: 0.1990 - val_accuracy: 0.8474\n",
      "Epoch 17/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1710 - accuracy: 0.8678 - val_loss: 0.2071 - val_accuracy: 0.8387\n",
      "Epoch 18/80\n",
      "55/55 [==============================] - 17s 302ms/step - loss: 0.1641 - accuracy: 0.8723 - val_loss: 0.2112 - val_accuracy: 0.8392\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 19/80\n",
      "55/55 [==============================] - 17s 302ms/step - loss: 0.1401 - accuracy: 0.8970 - val_loss: 0.1892 - val_accuracy: 0.8583\n",
      "Epoch 20/80\n",
      "55/55 [==============================] - 17s 307ms/step - loss: 0.1264 - accuracy: 0.9090 - val_loss: 0.1887 - val_accuracy: 0.8599\n",
      "Epoch 21/80\n",
      "55/55 [==============================] - 17s 310ms/step - loss: 0.1196 - accuracy: 0.9163 - val_loss: 0.1899 - val_accuracy: 0.8594\n",
      "Epoch 22/80\n",
      "55/55 [==============================] - 17s 313ms/step - loss: 0.1147 - accuracy: 0.9201 - val_loss: 0.1900 - val_accuracy: 0.8599\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 23/80\n",
      "55/55 [==============================] - 17s 307ms/step - loss: 0.1099 - accuracy: 0.9238 - val_loss: 0.1879 - val_accuracy: 0.8638\n",
      "Epoch 24/80\n",
      "55/55 [==============================] - 17s 305ms/step - loss: 0.1087 - accuracy: 0.9252 - val_loss: 0.1881 - val_accuracy: 0.8632\n",
      "Epoch 25/80\n",
      "55/55 [==============================] - 16s 300ms/step - loss: 0.1076 - accuracy: 0.9263 - val_loss: 0.1882 - val_accuracy: 0.8638\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 26/80\n",
      "55/55 [==============================] - 17s 308ms/step - loss: 0.1070 - accuracy: 0.9278 - val_loss: 0.1881 - val_accuracy: 0.8638\n",
      "Epoch 27/80\n",
      "55/55 [==============================] - 17s 304ms/step - loss: 0.1068 - accuracy: 0.9275 - val_loss: 0.1882 - val_accuracy: 0.8638\n",
      "Reduced learning rate to 1.0000001537946446e-07.\n",
      "Epoch 28/80\n",
      "55/55 [==============================] - 17s 306ms/step - loss: 0.1070 - accuracy: 0.9268 - val_loss: 0.1882 - val_accuracy: 0.8643\n"
     ]
    }
   ],
   "source": [
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=256, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_low_frequency_noise_multidim(data, snr, frequency_range=(0, 5), sample_rate=300):\n",
    "    data_power = np.mean(data ** 2)\n",
    "    noise_power = data_power / (10 ** (snr / 10))\n",
    "    t = np.arange(data.shape[-1]) / sample_rate \n",
    "    noise_frequencies = np.random.uniform(frequency_range[0], frequency_range[1], size=data.shape[-1])\n",
    "    noise = np.sqrt(noise_power) * np.sin(2 * np.pi * noise_frequencies * t)\n",
    "    noisy_data = data + noise[None, ...] \n",
    "    \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_low_frequency_noise_multidim(X_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.638237741672889\n",
      "Recall: 0.6822066900741324\n",
      "F1 Score: 0.6574919908350823\n",
      "Accuracy: 0.7518101367658889\n",
      "Class 1 - Precision: 0.4657039711191336, Recall: 0.5682819383259912, F1 Score: 0.511904761904762\n",
      "Class 2 - Precision: 0.8568548387096774, Recall: 0.8494337108594271, F1 Score: 0.8531281365005018\n",
      "Class 3 - Precision: 0.6470588235294118, Recall: 0.6111111111111112, F1 Score: 0.6285714285714287\n",
      "Class 4 - Precision: 0.5833333333333334, Recall: 0.7, F1 Score: 0.6363636363636365\n",
      "Class 1 Accuracy: 0.9010458567980691\n",
      "Class 2 Accuracy: 0.8234111021721641\n",
      "Class 3 Accuracy: 0.7855993563958166\n",
      "Class 4 Accuracy: 0.9935639581657281\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_low_frequency_noise_multidim(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8268610002435349\n",
      "Recall: 0.7766360935488308\n",
      "F1 Score: 0.79900227515049\n",
      "Accuracy: 0.8382944489139179\n",
      "Class 1 - Precision: 0.7955555555555556, Recall: 0.788546255506608, F1 Score: 0.7920353982300885\n",
      "Class 2 - Precision: 0.87997432605905, Recall: 0.9133910726182545, F1 Score: 0.8963713631905851\n",
      "Class 3 - Precision: 0.7569141193595342, Recall: 0.7046070460704607, F1 Score: 0.7298245614035087\n",
      "Class 4 - Precision: 0.875, Recall: 0.7, F1 Score: 0.7777777777777777\n",
      "Class 1 Accuracy: 0.9621882542236525\n",
      "Class 2 Accuracy: 0.8724859211584876\n",
      "Class 3 Accuracy: 0.8451327433628318\n",
      "Class 4 Accuracy: 0.996781979082864\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_high_frequency_noise_multidim(data, snr, frequency_range=(0, 200), sample_rate=300):\n",
    "    data_power = np.mean(data ** 2)\n",
    "    noise_power = data_power / (10 ** (snr / 10))\n",
    "    t = np.arange(data.shape[-1]) / sample_rate \n",
    "    noise_frequencies = np.random.uniform(frequency_range[0], frequency_range[1], size=data.shape[-1])\n",
    "    noise = np.sqrt(noise_power) * np.sin(2 * np.pi * noise_frequencies * t)\n",
    "    noisy_data = data + noise[None, ...] \n",
    "    \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_high_frequency_noise_multidim(X_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5788805359763913\n",
      "Recall: 0.7016657998766753\n",
      "F1 Score: 0.6134877160157673\n",
      "Accuracy: 0.7477876106194691\n",
      "Class 1 - Precision: 0.5020408163265306, Recall: 0.5418502202643172, F1 Score: 0.5211864406779662\n",
      "Class 2 - Precision: 0.8522033898305085, Recall: 0.8374417055296469, F1 Score: 0.844758064516129\n",
      "Class 3 - Precision: 0.6475524475524476, Recall: 0.6273712737127372, F1 Score: 0.6373021335168617\n",
      "Class 4 - Precision: 0.3137254901960784, Recall: 0.8, F1 Score: 0.45070422535211263\n",
      "Class 1 Accuracy: 0.9090909090909091\n",
      "Class 2 Accuracy: 0.8141592920353983\n",
      "Class 3 Accuracy: 0.7880128720836685\n",
      "Class 4 Accuracy: 0.9843121480289622\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_high_frequency_noise_multidim(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8320141311787147\n",
      "Recall: 0.764621841232309\n",
      "F1 Score: 0.791913461421289\n",
      "Accuracy: 0.8499597747385358\n",
      "Class 1 - Precision: 0.7991452991452992, Recall: 0.8237885462555066, F1 Score: 0.8112798264642083\n",
      "Class 2 - Precision: 0.883248730964467, Recall: 0.927381745502998, F1 Score: 0.9047773805654858\n",
      "Class 3 - Precision: 0.7885196374622356, Recall: 0.7073170731707317, F1 Score: 0.7457142857142857\n",
      "Class 4 - Precision: 0.8571428571428571, Recall: 0.6, F1 Score: 0.7058823529411764\n",
      "Class 1 Accuracy: 0.9650040225261464\n",
      "Class 2 Accuracy: 0.8821399839098955\n",
      "Class 3 Accuracy: 0.8567980691874497\n",
      "Class 4 Accuracy: 0.99597747385358\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
