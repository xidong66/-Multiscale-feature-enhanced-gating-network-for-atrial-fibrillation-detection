{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\database\\\\cinc2017denoise.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4500, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 4500, 32)     640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 4500, 32)     128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 4500, 32)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2250, 32)     3104        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2250, 32)     128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2250, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2250, 32)     3104        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2250, 32)     1056        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2250, 32)     128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2250, 32)     128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2250, 32)     0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2250, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1125, 64)     6208        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1125, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1125, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1125, 64)     12352       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1125, 64)     2112        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1125, 64)     256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1125, 64)     256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1125, 64)     0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1125, 64)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 563, 128)     24704       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 563, 128)     512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 563, 128)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 563, 128)     49280       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 563, 128)     8320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 563, 128)     512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 563, 128)     512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 563, 128)     0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 563, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 128)          99072       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 128)          99072       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 128)          0           gru[0][0]                        \n",
      "                                                                 gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            516         tf.__operators__.add[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 312,356\n",
      "Trainable params: 310,948\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dropout, Dense,MaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x, filters, kernel_size, strides):\n",
    "    shortcut = x\n",
    "    # 主卷积路径\n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 如果shortcut的形状与x不匹配，则调整shortcut\n",
    "    if shortcut.shape[-1] != x.shape[-1] or shortcut.shape[-2] != x.shape[-2]:\n",
    "        shortcut = Conv1D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # 添加跳过连接\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def resnet(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(32, 19, strides=1, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = residual_block(x, 32, 3, 2)\n",
    "    x = residual_block(x, 64, 3, 2)\n",
    "    x = residual_block(x, 128, 3, 2)\n",
    "    x1 = GRU(128, return_sequences=False)(x)\n",
    "    x2 = GRU(128, return_sequences=False)(x)\n",
    "    x=x1+x2\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "model =resnet((4500, 1), 4)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "55/55 [==============================] - 31s 340ms/step - loss: 0.4170 - accuracy: 0.5834 - val_loss: 0.4386 - val_accuracy: 0.5755\n",
      "Epoch 2/80\n",
      "55/55 [==============================] - 17s 319ms/step - loss: 0.4037 - accuracy: 0.5954 - val_loss: 0.4157 - val_accuracy: 0.5831\n",
      "Epoch 3/80\n",
      "55/55 [==============================] - 17s 308ms/step - loss: 0.3946 - accuracy: 0.6026 - val_loss: 0.3971 - val_accuracy: 0.6005\n",
      "Epoch 4/80\n",
      "55/55 [==============================] - 17s 308ms/step - loss: 0.3778 - accuracy: 0.6340 - val_loss: 0.3846 - val_accuracy: 0.6300\n",
      "Epoch 5/80\n",
      "55/55 [==============================] - 17s 312ms/step - loss: 0.3537 - accuracy: 0.6643 - val_loss: 0.3421 - val_accuracy: 0.6665\n",
      "Epoch 6/80\n",
      "55/55 [==============================] - 17s 309ms/step - loss: 0.3187 - accuracy: 0.7076 - val_loss: 0.3250 - val_accuracy: 0.6943\n",
      "Epoch 7/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.2916 - accuracy: 0.7417 - val_loss: 0.3073 - val_accuracy: 0.7210\n",
      "Epoch 8/80\n",
      "55/55 [==============================] - 17s 309ms/step - loss: 0.2686 - accuracy: 0.7672 - val_loss: 0.2657 - val_accuracy: 0.7657\n",
      "Epoch 9/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.2442 - accuracy: 0.7934 - val_loss: 0.2533 - val_accuracy: 0.7820\n",
      "Epoch 10/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.2356 - accuracy: 0.8019 - val_loss: 0.2477 - val_accuracy: 0.8000\n",
      "Epoch 11/80\n",
      "55/55 [==============================] - 18s 321ms/step - loss: 0.2208 - accuracy: 0.8177 - val_loss: 0.2349 - val_accuracy: 0.8065\n",
      "Epoch 12/80\n",
      "55/55 [==============================] - 17s 307ms/step - loss: 0.2069 - accuracy: 0.8344 - val_loss: 0.2294 - val_accuracy: 0.8147\n",
      "Epoch 13/80\n",
      "55/55 [==============================] - 17s 311ms/step - loss: 0.1992 - accuracy: 0.8410 - val_loss: 0.2309 - val_accuracy: 0.8082\n",
      "Epoch 14/80\n",
      "55/55 [==============================] - 17s 319ms/step - loss: 0.1870 - accuracy: 0.8514 - val_loss: 0.2296 - val_accuracy: 0.8338\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 15/80\n",
      "55/55 [==============================] - 17s 308ms/step - loss: 0.1599 - accuracy: 0.8801 - val_loss: 0.1999 - val_accuracy: 0.8534\n",
      "Epoch 16/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1493 - accuracy: 0.8909 - val_loss: 0.1972 - val_accuracy: 0.8561\n",
      "Epoch 17/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1440 - accuracy: 0.8938 - val_loss: 0.1985 - val_accuracy: 0.8550\n",
      "Epoch 18/80\n",
      "55/55 [==============================] - 17s 313ms/step - loss: 0.1394 - accuracy: 0.8974 - val_loss: 0.1967 - val_accuracy: 0.8550\n",
      "Epoch 19/80\n",
      "55/55 [==============================] - 18s 319ms/step - loss: 0.1363 - accuracy: 0.9017 - val_loss: 0.1961 - val_accuracy: 0.8589\n",
      "Epoch 20/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1320 - accuracy: 0.9055 - val_loss: 0.1968 - val_accuracy: 0.8583\n",
      "Epoch 21/80\n",
      "55/55 [==============================] - 17s 314ms/step - loss: 0.1273 - accuracy: 0.9106 - val_loss: 0.2023 - val_accuracy: 0.8523\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 22/80\n",
      "55/55 [==============================] - 17s 308ms/step - loss: 0.1217 - accuracy: 0.9174 - val_loss: 0.1965 - val_accuracy: 0.8605\n",
      "Epoch 23/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1201 - accuracy: 0.9196 - val_loss: 0.1962 - val_accuracy: 0.8605\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 24/80\n",
      "55/55 [==============================] - 17s 307ms/step - loss: 0.1187 - accuracy: 0.9208 - val_loss: 0.1961 - val_accuracy: 0.8610\n"
     ]
    }
   ],
   "source": [
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=256, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_low_frequency_noise_multidim(data, snr, frequency_range=(0, 5), sample_rate=300):\n",
    "    data_power = np.mean(data ** 2)\n",
    "    noise_power = data_power / (10 ** (snr / 10))\n",
    "    t = np.arange(data.shape[-1]) / sample_rate \n",
    "    noise_frequencies = np.random.uniform(frequency_range[0], frequency_range[1], size=data.shape[-1])\n",
    "    noise = np.sqrt(noise_power) * np.sin(2 * np.pi * noise_frequencies * t)\n",
    "    noisy_data = data + noise[None, ...] \n",
    "    \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_low_frequency_noise_multidim(X_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7261326919721017\n",
      "Recall: 0.6023705343205131\n",
      "F1 Score: 0.6475079168333124\n",
      "Accuracy: 0.7546259050683829\n",
      "Class 1 - Precision: 0.6325301204819277, Recall: 0.46255506607929514, F1 Score: 0.5343511450381679\n",
      "Class 2 - Precision: 0.8309768637532133, Recall: 0.8614257161892072, F1 Score: 0.845927379784102\n",
      "Class 3 - Precision: 0.6228419654714475, Recall: 0.6355013550135501, F1 Score: 0.6291079812206573\n",
      "Class 4 - Precision: 0.8181818181818182, Recall: 0.45, F1 Score: 0.5806451612903226\n",
      "Class 1 Accuracy: 0.9263877715205149\n",
      "Class 2 Accuracy: 0.8105390185036203\n",
      "Class 3 Accuracy: 0.7775543041029767\n",
      "Class 4 Accuracy: 0.994770716009654\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_low_frequency_noise_multidim(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8242641422800469\n",
      "Recall: 0.7278880339140612\n",
      "F1 Score: 0.7631779526889068\n",
      "Accuracy: 0.832260659694288\n",
      "Class 1 - Precision: 0.7383966244725738, Recall: 0.7709251101321586, F1 Score: 0.7543103448275862\n",
      "Class 2 - Precision: 0.8686176836861769, Recall: 0.9293804130579614, F1 Score: 0.8979723205664628\n",
      "Class 3 - Precision: 0.7733755942947702, Recall: 0.6612466124661247, F1 Score: 0.7129291453615779\n",
      "Class 4 - Precision: 0.9166666666666666, Recall: 0.55, F1 Score: 0.6874999999999999\n",
      "Class 1 Accuracy: 0.9541432019308126\n",
      "Class 2 Accuracy: 0.8724859211584876\n",
      "Class 3 Accuracy: 0.8419147224456959\n",
      "Class 4 Accuracy: 0.99597747385358\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_high_frequency_noise_multidim(data, snr, frequency_range=(0, 200), sample_rate=300):\n",
    "    data_power = np.mean(data ** 2)\n",
    "    noise_power = data_power / (10 ** (snr / 10))\n",
    "    t = np.arange(data.shape[-1]) / sample_rate \n",
    "    noise_frequencies = np.random.uniform(frequency_range[0], frequency_range[1], size=data.shape[-1])\n",
    "    noise = np.sqrt(noise_power) * np.sin(2 * np.pi * noise_frequencies * t)\n",
    "    noisy_data = data + noise[None, ...] \n",
    "    \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_high_frequency_noise_multidim(X_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7420129997154645\n",
      "Recall: 0.6119514720807047\n",
      "F1 Score: 0.6595299959210408\n",
      "Accuracy: 0.7614641995172968\n",
      "Class 1 - Precision: 0.6736111111111112, Recall: 0.42731277533039647, F1 Score: 0.522911051212938\n",
      "Class 2 - Precision: 0.8361075544174136, Recall: 0.8700866089273818, F1 Score: 0.8527587332680379\n",
      "Class 3 - Precision: 0.625, Recall: 0.6504065040650406, F1 Score: 0.6374501992031872\n",
      "Class 4 - Precision: 0.8333333333333334, Recall: 0.5, F1 Score: 0.625\n",
      "Class 1 Accuracy: 0.9288012872083669\n",
      "Class 2 Accuracy: 0.8185840707964602\n",
      "Class 3 Accuracy: 0.7803700724054706\n",
      "Class 4 Accuracy: 0.995172968624296\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_high_frequency_noise_multidim(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8359427795756856\n",
      "Recall: 0.730261382538149\n",
      "F1 Score: 0.7706418168792397\n",
      "Accuracy: 0.8366854384553499\n",
      "Class 1 - Precision: 0.7863636363636364, Recall: 0.762114537444934, F1 Score: 0.7740492170022372\n",
      "Class 2 - Precision: 0.8696194635059263, Recall: 0.9287141905396402, F1 Score: 0.8981958762886597\n",
      "Class 3 - Precision: 0.7711213517665131, Recall: 0.6802168021680217, F1 Score: 0.7228221742260621\n",
      "Class 4 - Precision: 0.9166666666666666, Recall: 0.55, F1 Score: 0.6874999999999999\n",
      "Class 1 Accuracy: 0.9593724859211585\n",
      "Class 2 Accuracy: 0.8728881737731295\n",
      "Class 3 Accuracy: 0.8451327433628318\n",
      "Class 4 Accuracy: 0.99597747385358\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
