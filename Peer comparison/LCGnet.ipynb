{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\database\\\\cinc2017denoise.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix  # 混淆矩阵\n",
    "from sklearn.model_selection import train_test_split  # 划分数据集\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn import metrics  # 模型评估\n",
    "from keras import Input\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, Add, Multiply, \\\n",
    "    GlobalAveragePooling1D, Concatenate, AvgPool1D, BatchNormalization, ELU, Activation,  SeparableConv1D,Conv2D, Lambda,\\\n",
    "    Reshape,GlobalMaxPooling1D,GRU\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras_flops import get_flops\n",
    "D = 32\n",
    "S = 16\n",
    "C = D+S\n",
    "r1 = 4\n",
    "r2 = 2\n",
    "\n",
    "def DC_Block1(input, k, c, padding='same'):\n",
    "\n",
    "    conv1_1 = SeparableConv1D(c,kernel_size=k, strides=1, padding=padding)(input)\n",
    "    conv1_1 = BatchNormalization(momentum=0.99, epsilon=0.001)(conv1_1)\n",
    "    conv1_1 = ELU()(conv1_1)\n",
    "\n",
    "    # conv1_1 = Conv1D(filters=c, kernel_size=1, strides=1)(conv1_1)\n",
    "    # conv1_1 = BatchNormalization(momentum=0.99, epsilon=0.001)(conv1_1)\n",
    "    # conv1_1 = ELU()(conv1_1)\n",
    "    conv1_1 = MaxPooling1D(pool_size=2, strides=2)(conv1_1)\n",
    "\n",
    "    return conv1_1\n",
    "\n",
    "def Block1(input, k, c, padding='same'):\n",
    "\n",
    "    conv1_1 = Conv1D(filters=c, kernel_size=k, strides=1, padding=padding)(input)\n",
    "    conv1_1 = BatchNormalization(momentum=0.99, epsilon=0.001)(conv1_1)\n",
    "    conv1_1 = ELU()(conv1_1)\n",
    "    conv1_1 = MaxPooling1D(pool_size=2, strides=2)(conv1_1)\n",
    "    return conv1_1\n",
    "\n",
    "def senet(inputs, c, r):\n",
    "\n",
    "    x = GlobalAveragePooling1D()(inputs)\n",
    "    x = Dense(int(x.shape[-1]) // r, activation='relu')(x)\n",
    "    x = Dense(c, activation='sigmoid')(x)\n",
    "    return x\n",
    "\n",
    "def models(input_shape):\n",
    "\n",
    "    x0 = Conv1D(filters=D, kernel_size=1, strides=1)(input_shape)\n",
    "    x0 = BatchNormalization(momentum=0.99, epsilon=0.001)(x0)\n",
    "    x0 = ELU()(x0)\n",
    "\n",
    "    # y0 = Conv1D(filters=S, kernel_size=1, strides=1)(input_shape)\n",
    "    # y0 = BatchNormalization(momentum=0.99, epsilon=0.001)(y0)\n",
    "    # y0 = ELU()(y0)\n",
    "\n",
    "    # 1\n",
    "    x1 = DC_Block1(x0, k=3, c=D)\n",
    "    y1 = Block1(input_shape, k=3, c=S)\n",
    "\n",
    "    z1 = senet(x1, c=S, r=r1)\n",
    "    z2 = senet(y1, c=D, r=r2)\n",
    "\n",
    "    x1 = Multiply()([x1, z2])\n",
    "    y1 = Multiply()([y1, z1])\n",
    "\n",
    "    # 2\n",
    "    x2 = DC_Block1(x1, k=3, c=D)\n",
    "    y2 = Block1(y1, k=3, c=S)\n",
    "\n",
    "    z1 = senet(x2, c=S, r=r1)\n",
    "    z2 = senet(y2, c=D, r=r2)\n",
    "\n",
    "    x2 = Multiply()([x2, z2])\n",
    "    y2 = Multiply()([y2, z1])\n",
    "\n",
    "    # 3\n",
    "    x3 = DC_Block1(x2, k=3, c=D)\n",
    "    y3 = Block1(y2, k=3, c=S)\n",
    "\n",
    "    z1 = senet(x3, c=S, r=r1)\n",
    "    z2 = senet(y3, c=D, r=r2)\n",
    "\n",
    "    x3 = Multiply()([x3, z2])\n",
    "    y3 = Multiply()([y3, z1])\n",
    "\n",
    "    # 4\n",
    "    x4 = DC_Block1(x3, k=3, c=D)\n",
    "    y4 = Block1(y3, k=3, c=S)\n",
    "\n",
    "    z1 = senet(x4, c=S, r=r1)\n",
    "    z2 = senet(y4, c=D, r=r2)\n",
    "\n",
    "    x4 = Multiply()([x4, z2])\n",
    "    y4 = Multiply()([y4, z1])\n",
    "\n",
    "    # 5\n",
    "    x5 = DC_Block1(x4, k=3, c=D)\n",
    "    y5 = Block1(y4, k=3, c=S)\n",
    "\n",
    "    z1 = senet(x5, c=S, r=r1)\n",
    "    z2 = senet(y5, c=D, r=r2)\n",
    "\n",
    "    x5 = Multiply()([x5, z2])\n",
    "    y5 = Multiply()([y5, z1])\n",
    "\n",
    "    # 6\n",
    "    x6 = DC_Block1(x5, k=3, c=D)\n",
    "    y6 = Block1(y5, k=3, c=S)\n",
    "\n",
    "    z1 = senet(x6, c=S, r=r1)\n",
    "    z2 = senet(y6, c=D, r=r2)\n",
    "    x6 = Multiply()([x6, z2])\n",
    "    y6 = Multiply()([y6, z1])\n",
    "\n",
    "    # 7\n",
    "    x7 = DC_Block1(x6, k=3, c=D)\n",
    "    y7 = Block1(y6, k=3, c=S)\n",
    "\n",
    "    z1 = senet(x7, c=S, r=r1)\n",
    "    z2 = senet(y7, c=D, r=r2)\n",
    "\n",
    "    x7 = Multiply()([x7, z2])\n",
    "    y7 = Multiply()([y7, z1])\n",
    "\n",
    "    # 8\n",
    "    x8 = DC_Block1(x7, k=3, c=D)\n",
    "    y8 = Block1(y7, k=3, c=S)\n",
    "\n",
    "    z1 = senet(x8, c=S, r=r1)\n",
    "    z2 = senet(y8, c=D, r=r2)\n",
    "\n",
    "    x8 = Multiply()([x8, z2])\n",
    "    y8 = Multiply()([y8, z1])\n",
    "\n",
    "    # 9\n",
    "    x9 = DC_Block1(x8, k=3, c=D)\n",
    "    y9 = Block1(y8, k=3, c=S)\n",
    "\n",
    "    z1 = senet(x9, c=S, r=r1)\n",
    "    z2 = senet(y9, c=D, r=r2)\n",
    "\n",
    "    x9 = Multiply()([x9, z2])\n",
    "    y9 = Multiply()([y9, z1])\n",
    "\n",
    "    s1 = Concatenate()([x1, y1])\n",
    "    s1 = GlobalAveragePooling1D()(s1)\n",
    "    s1 = Dense(C, activation='sigmoid')(s1)\n",
    "\n",
    "    s2 = Concatenate()([x2, y2])\n",
    "    s2 = GlobalAveragePooling1D()(s2)\n",
    "    s2 = Dense(C, activation='sigmoid')(s2)\n",
    "\n",
    "    s3 = Concatenate()([x3, y3])\n",
    "    s3 = GlobalAveragePooling1D()(s3)\n",
    "    s3 = Dense(C, activation='sigmoid')(s3)\n",
    "\n",
    "    c1 = Concatenate()([s1, s2, s3])\n",
    "    c1 = Reshape((3, C, 1), input_shape=(None, 3 * C))(c1)\n",
    "    c1 = Conv2D(filters=8, kernel_size=(3, 1), strides=1)(c1)\n",
    "    c1 = BatchNormalization(momentum=0.99, epsilon=0.001)(c1)\n",
    "    c1 = ELU()(c1)\n",
    "    c1 = Flatten()(c1)\n",
    "\n",
    "    s4 = Concatenate()([x4, y4])\n",
    "    s4 = GlobalAveragePooling1D()(s4)\n",
    "    s4 = Dense(C, activation='sigmoid')(s4)\n",
    "\n",
    "    s5 = Concatenate()([x5, y5])\n",
    "    s5 = GlobalAveragePooling1D()(s5)\n",
    "    s5 = Dense(C, activation='sigmoid')(s5)\n",
    "\n",
    "    s6 = Concatenate()([x6, y6])\n",
    "    s6 = GlobalAveragePooling1D()(s6)\n",
    "    s6 = Dense(C, activation='sigmoid')(s6)\n",
    "\n",
    "    c2 = Concatenate()([s4, s5, s6])\n",
    "    c2 = Reshape((3, C, 1), input_shape=(None, 3 * C))(c2)\n",
    "    c2 = Conv2D(filters=8, kernel_size=(3, 1), strides=1)(c2)\n",
    "    c2 = BatchNormalization(momentum=0.99, epsilon=0.001)(c2)\n",
    "    c2 = ELU()(c2)\n",
    "    c2 = Flatten()(c2)\n",
    "\n",
    "    s7 = Concatenate()([x7, y7])\n",
    "    s7 = GlobalAveragePooling1D()(s7)\n",
    "    s7 = Dense(C, activation='sigmoid')(s7)\n",
    "\n",
    "    s8 = Concatenate()([x8, y8])\n",
    "    s8 = GlobalAveragePooling1D()(s8)\n",
    "    s8 = Dense(C, activation='sigmoid')(s8)\n",
    "\n",
    "    s9 = Concatenate()([x9, y9])\n",
    "    s9 = GlobalAveragePooling1D()(s9)\n",
    "    s9 = Dense(C, activation='sigmoid')(s9)\n",
    "\n",
    "    c3 = Concatenate()([s7, s8, s9])\n",
    "    c3 = Reshape((3, C, 1), input_shape=(None, 3 * C))(c3)\n",
    "    c3 = Conv2D(filters=8, kernel_size=(3, 1), strides=1)(c3)\n",
    "    c3 = BatchNormalization(momentum=0.99, epsilon=0.001)(c3)\n",
    "    c3 = ELU()(c3)\n",
    "    c3 = Flatten()(c3)\n",
    "\n",
    "    # 重新用卷积选择，不用赋权重\n",
    "    out = Concatenate()([c1, c2, c3])\n",
    "    out = Reshape((3, 384, 1),  input_shape=(None, 1152))(out)\n",
    "    out = Conv2D(filters=1, kernel_size=(3, 3), strides=1)(out)\n",
    "    out = BatchNormalization(momentum=0.99, epsilon=0.001)(out)\n",
    "    out = ELU()(out)\n",
    "    out = Flatten()(out)\n",
    "\n",
    "    out = Dense(4, activation='softmax')(out)\n",
    "    out = Model(inputs=[input_shape], outputs=[out], name=\"RF_CNN\")\n",
    "    return out\n",
    "inputs = Input(shape=(4500, 1))\n",
    "\n",
    "model = models(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      " 6/55 [==>...........................] - ETA: 12s - loss: 0.5030 - accuracy: 0.5885WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1192s vs `on_train_batch_end` time: 0.1200s). Check your callbacks.\n",
      "55/55 [==============================] - 32s 297ms/step - loss: 0.3738 - accuracy: 0.6495 - val_loss: 0.7209 - val_accuracy: 0.0856\n",
      "Epoch 2/80\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 0.3062 - accuracy: 0.7187 - val_loss: 0.7080 - val_accuracy: 0.0856\n",
      "Epoch 3/80\n",
      "55/55 [==============================] - 14s 254ms/step - loss: 0.2768 - accuracy: 0.7556 - val_loss: 0.6876 - val_accuracy: 0.0861\n",
      "Epoch 4/80\n",
      "55/55 [==============================] - 14s 252ms/step - loss: 0.2608 - accuracy: 0.7733 - val_loss: 0.6622 - val_accuracy: 0.2850\n",
      "Epoch 5/80\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 0.2447 - accuracy: 0.7897 - val_loss: 0.6359 - val_accuracy: 0.6076\n",
      "Epoch 6/80\n",
      "55/55 [==============================] - 14s 254ms/step - loss: 0.2348 - accuracy: 0.7983 - val_loss: 0.5871 - val_accuracy: 0.4937\n",
      "Epoch 7/80\n",
      "55/55 [==============================] - 14s 254ms/step - loss: 0.2235 - accuracy: 0.8095 - val_loss: 0.5632 - val_accuracy: 0.4589\n",
      "Epoch 8/80\n",
      "55/55 [==============================] - 14s 252ms/step - loss: 0.2146 - accuracy: 0.8217 - val_loss: 0.5603 - val_accuracy: 0.3515\n",
      "Epoch 9/80\n",
      "55/55 [==============================] - 14s 254ms/step - loss: 0.2087 - accuracy: 0.8261 - val_loss: 0.5001 - val_accuracy: 0.4071\n",
      "Epoch 10/80\n",
      "55/55 [==============================] - 14s 254ms/step - loss: 0.2051 - accuracy: 0.8320 - val_loss: 0.4300 - val_accuracy: 0.5379\n",
      "Epoch 11/80\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 0.1911 - accuracy: 0.8432 - val_loss: 0.3572 - val_accuracy: 0.6812\n",
      "Epoch 12/80\n",
      "55/55 [==============================] - 14s 254ms/step - loss: 0.1881 - accuracy: 0.8485 - val_loss: 0.2788 - val_accuracy: 0.7629\n",
      "Epoch 13/80\n",
      "55/55 [==============================] - 14s 254ms/step - loss: 0.1831 - accuracy: 0.8520 - val_loss: 0.2276 - val_accuracy: 0.8147\n",
      "Epoch 14/80\n",
      "55/55 [==============================] - 14s 255ms/step - loss: 0.1749 - accuracy: 0.8595 - val_loss: 0.2735 - val_accuracy: 0.7695\n",
      "Epoch 15/80\n",
      "55/55 [==============================] - 14s 257ms/step - loss: 0.1683 - accuracy: 0.8659 - val_loss: 0.2736 - val_accuracy: 0.7777\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 16/80\n",
      "55/55 [==============================] - 14s 253ms/step - loss: 0.1474 - accuracy: 0.8839 - val_loss: 0.2193 - val_accuracy: 0.8272\n",
      "Epoch 17/80\n",
      "55/55 [==============================] - 14s 255ms/step - loss: 0.1388 - accuracy: 0.8914 - val_loss: 0.2146 - val_accuracy: 0.8338\n",
      "Epoch 18/80\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 0.1350 - accuracy: 0.8948 - val_loss: 0.2140 - val_accuracy: 0.8305\n",
      "Epoch 19/80\n",
      "55/55 [==============================] - 14s 253ms/step - loss: 0.1321 - accuracy: 0.9006 - val_loss: 0.2191 - val_accuracy: 0.8332\n",
      "Epoch 20/80\n",
      "55/55 [==============================] - 14s 255ms/step - loss: 0.1312 - accuracy: 0.8991 - val_loss: 0.2164 - val_accuracy: 0.8272\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 21/80\n",
      "55/55 [==============================] - 14s 256ms/step - loss: 0.1270 - accuracy: 0.9036 - val_loss: 0.2160 - val_accuracy: 0.8332\n",
      "Epoch 22/80\n",
      "55/55 [==============================] - 14s 251ms/step - loss: 0.1264 - accuracy: 0.9045 - val_loss: 0.2167 - val_accuracy: 0.8327\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 23/80\n",
      "55/55 [==============================] - 14s 251ms/step - loss: 0.1257 - accuracy: 0.9045 - val_loss: 0.2172 - val_accuracy: 0.8327\n"
     ]
    }
   ],
   "source": [
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=256, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_low_frequency_noise_multidim(data, snr, frequency_range=(0, 5), sample_rate=300):\n",
    "    data_power = np.mean(data ** 2)\n",
    "    noise_power = data_power / (10 ** (snr / 10))\n",
    "    t = np.arange(data.shape[-1]) / sample_rate \n",
    "    noise_frequencies = np.random.uniform(frequency_range[0], frequency_range[1], size=data.shape[-1])\n",
    "    noise = np.sqrt(noise_power) * np.sin(2 * np.pi * noise_frequencies * t)\n",
    "    noisy_data = data + noise[None, ...] \n",
    "    \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_low_frequency_noise_multidim(X_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.46365647377138297\n",
      "Recall: 0.5899499411878457\n",
      "F1 Score: 0.4721728802938484\n",
      "Accuracy: 0.5728077232502011\n",
      "Class 1 - Precision: 0.2073170731707317, Recall: 0.6740088105726872, F1 Score: 0.3170984455958549\n",
      "Class 2 - Precision: 0.8428819444444444, Recall: 0.6469020652898068, F1 Score: 0.7320015077271014\n",
      "Class 3 - Precision: 0.5218181818181818, Recall: 0.3888888888888889, F1 Score: 0.44565217391304346\n",
      "Class 4 - Precision: 0.2826086956521739, Recall: 0.65, F1 Score: 0.3939393939393939\n",
      "Class 1 Accuracy: 0.7349155269509252\n",
      "Class 2 Accuracy: 0.7139983909895414\n",
      "Class 3 Accuracy: 0.7127916331456154\n",
      "Class 4 Accuracy: 0.9839098954143202\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_low_frequency_noise_multidim(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6403814831093506\n",
      "Recall: 0.6518726504437591\n",
      "F1 Score: 0.6268149680885531\n",
      "Accuracy: 0.7377312952534192\n",
      "Class 1 - Precision: 0.4657534246575342, Recall: 0.748898678414097, F1 Score: 0.5743243243243242\n",
      "Class 2 - Precision: 0.8052412150089339, Recall: 0.9007328447701533, F1 Score: 0.8503144654088051\n",
      "Class 3 - Precision: 0.7115839243498818, Recall: 0.4078590785907859, F1 Score: 0.5185185185185186\n",
      "Class 4 - Precision: 0.5789473684210527, Recall: 0.55, F1 Score: 0.5641025641025641\n",
      "Class 1 Accuracy: 0.8986323411102172\n",
      "Class 2 Accuracy: 0.8085277554304103\n",
      "Class 3 Accuracy: 0.7751407884151247\n",
      "Class 4 Accuracy: 0.9931617055510861\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_high_frequency_noise_multidim(data, snr, frequency_range=(0, 200), sample_rate=300):\n",
    "    data_power = np.mean(data ** 2)\n",
    "    noise_power = data_power / (10 ** (snr / 10))\n",
    "    t = np.arange(data.shape[-1]) / sample_rate \n",
    "    noise_frequencies = np.random.uniform(frequency_range[0], frequency_range[1], size=data.shape[-1])\n",
    "    noise = np.sqrt(noise_power) * np.sin(2 * np.pi * noise_frequencies * t)\n",
    "    noisy_data = data + noise[None, ...] \n",
    "    \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_high_frequency_noise_multidim(X_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.44831876434424633\n",
      "Recall: 0.5693768637764447\n",
      "F1 Score: 0.4581045456428349\n",
      "Accuracy: 0.5639581657280772\n",
      "Class 1 - Precision: 0.20646067415730338, Recall: 0.6475770925110133, F1 Score: 0.31309904153354634\n",
      "Class 2 - Precision: 0.8407079646017699, Recall: 0.6329113924050633, F1 Score: 0.7221588749524896\n",
      "Class 3 - Precision: 0.490787269681742, Recall: 0.3970189701897019, F1 Score: 0.4389513108614232\n",
      "Class 4 - Precision: 0.2553191489361702, Recall: 0.6, F1 Score: 0.3582089552238805\n",
      "Class 1 Accuracy: 0.7405470635559132\n",
      "Class 2 Accuracy: 0.7059533386967015\n",
      "Class 3 Accuracy: 0.6987127916331456\n",
      "Class 4 Accuracy: 0.9827031375703942\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_high_frequency_noise_multidim(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6340583036319235\n",
      "Recall: 0.6730238817703224\n",
      "F1 Score: 0.6324055361444203\n",
      "Accuracy: 0.7393403057119872\n",
      "Class 1 - Precision: 0.4704225352112676, Recall: 0.73568281938326, F1 Score: 0.5738831615120276\n",
      "Class 2 - Precision: 0.8024691358024691, Recall: 0.9093937375083277, F1 Score: 0.8525921299188006\n",
      "Class 3 - Precision: 0.7216748768472906, Recall: 0.3970189701897019, F1 Score: 0.5122377622377623\n",
      "Class 4 - Precision: 0.5416666666666666, Recall: 0.65, F1 Score: 0.5909090909090908\n",
      "Class 1 Accuracy: 0.9002413515687852\n",
      "Class 2 Accuracy: 0.8101367658889783\n",
      "Class 3 Accuracy: 0.7755430410297667\n",
      "Class 4 Accuracy: 0.9927594529364441\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
