{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\database\\\\cinc2017denoise.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Concatenate\n",
    "\n",
    "def ince_block(inputs, filters, strides=1):\n",
    "    x1 = Conv1D(filters, 3, strides=strides, padding='same')(inputs)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv1D(filters, 5, strides=1, padding='same')(inputs)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = Conv1D(filters, 9, strides=1, padding='same')(inputs)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    x4 = Conv1D(filters, 17, strides=1, padding='same')(inputs)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Activation('relu')(x4)\n",
    "\n",
    "    x = Concatenate()([x1, x2, x3, x4])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Reshape, Dense, Multiply\n",
    "def se_block(input_tensor, reduction_ratio=16):\n",
    "  channels = input_tensor.shape[-1]\n",
    "  x = GlobalAveragePooling1D()(input_tensor)\n",
    "  x = Reshape((1, channels))(x)\n",
    "  x = Dense(channels // reduction_ratio, activation='relu', use_bias=False)(x)\n",
    "  x = Dense(channels, activation='sigmoid', use_bias=False)(x)\n",
    "  x = Multiply()([input_tensor, x])\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4500, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 2250, 32)     128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2250, 32)     128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2250, 32)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1125, 32)     3104        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1125, 32)     128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1125, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1125, 32)     3104        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1125, 32)     1056        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 1125, 32)     128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1125, 32)     128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1125, 32)     0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1125, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 563, 64)      6208        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 563, 64)      256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 563, 64)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 563, 64)      12352       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 563, 64)      2112        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 563, 64)      256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 563, 64)      256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 563, 64)      0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 563, 64)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 282, 128)     24704       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 282, 128)     512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 282, 128)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 282, 128)     49280       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 282, 128)     8320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 282, 128)     512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 282, 128)     512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 282, 128)     0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 282, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 141, 256)     98560       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 141, 256)     1024        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 141, 256)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 141, 256)     196864      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 141, 256)     33024       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 141, 256)     1024        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 141, 256)     1024        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 141, 256)     0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 141, 256)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 256)          0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            1028        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 445,732\n",
      "Trainable params: 442,788\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x, filters, kernel_size, strides):\n",
    "    shortcut = x\n",
    "    # 主卷积路径\n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 如果shortcut的形状与x不匹配，则调整shortcut\n",
    "    if shortcut.shape[-1] != x.shape[-1] or shortcut.shape[-2] != x.shape[-2]:\n",
    "        shortcut = Conv1D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # 添加跳过连接\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def resnet(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(32, 3, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = residual_block(x, 32, 3, 2)\n",
    "    x = residual_block(x, 64, 3, 2)\n",
    "    x = residual_block(x, 128,3, 2)\n",
    "    x = residual_block(x, 256,3, 2)\n",
    "    x=GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "model =resnet((4500, 1), 4)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "55/55 [==============================] - 15s 84ms/step - loss: 0.3874 - accuracy: 0.6147 - val_loss: 0.4201 - val_accuracy: 0.6082\n",
      "Epoch 2/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.3323 - accuracy: 0.6851 - val_loss: 0.3736 - val_accuracy: 0.6185\n",
      "Epoch 3/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.3126 - accuracy: 0.7097 - val_loss: 0.3484 - val_accuracy: 0.6371\n",
      "Epoch 4/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.3004 - accuracy: 0.7292 - val_loss: 0.3308 - val_accuracy: 0.6768\n",
      "Epoch 5/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.2872 - accuracy: 0.7413 - val_loss: 0.3126 - val_accuracy: 0.7052\n",
      "Epoch 6/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.2803 - accuracy: 0.7508 - val_loss: 0.3231 - val_accuracy: 0.6872\n",
      "Epoch 7/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.2732 - accuracy: 0.7599 - val_loss: 0.3040 - val_accuracy: 0.7286\n",
      "Epoch 8/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.2653 - accuracy: 0.7677 - val_loss: 0.3227 - val_accuracy: 0.7046\n",
      "Epoch 9/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.2589 - accuracy: 0.7761 - val_loss: 0.3325 - val_accuracy: 0.6872\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 10/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.2361 - accuracy: 0.8029 - val_loss: 0.2612 - val_accuracy: 0.7766\n",
      "Epoch 11/80\n",
      "55/55 [==============================] - 4s 68ms/step - loss: 0.2265 - accuracy: 0.8165 - val_loss: 0.2587 - val_accuracy: 0.7837\n",
      "Epoch 12/80\n",
      "55/55 [==============================] - 4s 68ms/step - loss: 0.2219 - accuracy: 0.8195 - val_loss: 0.2554 - val_accuracy: 0.7831\n",
      "Epoch 13/80\n",
      "55/55 [==============================] - 4s 68ms/step - loss: 0.2178 - accuracy: 0.8248 - val_loss: 0.2538 - val_accuracy: 0.7891\n",
      "Epoch 14/80\n",
      "55/55 [==============================] - 4s 68ms/step - loss: 0.2146 - accuracy: 0.8284 - val_loss: 0.2522 - val_accuracy: 0.7896\n",
      "Epoch 15/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.2104 - accuracy: 0.8344 - val_loss: 0.2517 - val_accuracy: 0.7831\n",
      "Epoch 16/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.2075 - accuracy: 0.8376 - val_loss: 0.2485 - val_accuracy: 0.7880\n",
      "Epoch 17/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.2028 - accuracy: 0.8423 - val_loss: 0.2516 - val_accuracy: 0.7869\n",
      "Epoch 18/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1995 - accuracy: 0.8449 - val_loss: 0.2546 - val_accuracy: 0.7946\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 19/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1932 - accuracy: 0.8550 - val_loss: 0.2468 - val_accuracy: 0.7973\n",
      "Epoch 20/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1910 - accuracy: 0.8528 - val_loss: 0.2454 - val_accuracy: 0.7940\n",
      "Epoch 21/80\n",
      "55/55 [==============================] - 4s 68ms/step - loss: 0.1910 - accuracy: 0.8571 - val_loss: 0.2451 - val_accuracy: 0.7984\n",
      "Epoch 22/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1900 - accuracy: 0.8571 - val_loss: 0.2458 - val_accuracy: 0.7940\n",
      "Epoch 23/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1895 - accuracy: 0.8556 - val_loss: 0.2449 - val_accuracy: 0.7973\n",
      "Epoch 24/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1892 - accuracy: 0.8555 - val_loss: 0.2447 - val_accuracy: 0.8000\n",
      "Epoch 25/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1891 - accuracy: 0.8555 - val_loss: 0.2456 - val_accuracy: 0.8000\n",
      "Epoch 26/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1879 - accuracy: 0.8590 - val_loss: 0.2448 - val_accuracy: 0.8011\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 27/80\n",
      "55/55 [==============================] - 4s 70ms/step - loss: 0.1882 - accuracy: 0.8586 - val_loss: 0.2446 - val_accuracy: 0.8011\n",
      "Epoch 28/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1867 - accuracy: 0.8607 - val_loss: 0.2445 - val_accuracy: 0.8016\n",
      "Epoch 29/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1874 - accuracy: 0.8593 - val_loss: 0.2445 - val_accuracy: 0.8000\n",
      "Epoch 30/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1882 - accuracy: 0.8569 - val_loss: 0.2444 - val_accuracy: 0.8011\n",
      "Epoch 31/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1878 - accuracy: 0.8581 - val_loss: 0.2444 - val_accuracy: 0.8016\n",
      "Epoch 32/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1872 - accuracy: 0.8586 - val_loss: 0.2444 - val_accuracy: 0.8016\n",
      "Reduced learning rate to 1.0000001537946446e-07.\n",
      "Epoch 33/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1874 - accuracy: 0.8580 - val_loss: 0.2444 - val_accuracy: 0.8016\n",
      "Epoch 34/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1871 - accuracy: 0.8586 - val_loss: 0.2444 - val_accuracy: 0.8016\n",
      "Epoch 35/80\n",
      "55/55 [==============================] - 4s 68ms/step - loss: 0.1877 - accuracy: 0.8596 - val_loss: 0.2444 - val_accuracy: 0.8016\n",
      "Epoch 36/80\n",
      "55/55 [==============================] - 4s 68ms/step - loss: 0.1863 - accuracy: 0.8617 - val_loss: 0.2444 - val_accuracy: 0.8016\n",
      "Epoch 37/80\n",
      "55/55 [==============================] - 4s 68ms/step - loss: 0.1873 - accuracy: 0.8606 - val_loss: 0.2444 - val_accuracy: 0.8016\n",
      "Epoch 38/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1873 - accuracy: 0.8576 - val_loss: 0.2444 - val_accuracy: 0.8016\n",
      "Reduced learning rate to 1.000000171558213e-08.\n",
      "Epoch 39/80\n",
      "55/55 [==============================] - 4s 70ms/step - loss: 0.1874 - accuracy: 0.8574 - val_loss: 0.2444 - val_accuracy: 0.8016\n",
      "Epoch 40/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1879 - accuracy: 0.8611 - val_loss: 0.2444 - val_accuracy: 0.8011\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 41/80\n",
      "55/55 [==============================] - 4s 69ms/step - loss: 0.1872 - accuracy: 0.8572 - val_loss: 0.2444 - val_accuracy: 0.8016\n"
     ]
    }
   ],
   "source": [
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=256, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_low_frequency_noise_multidim(data, snr, frequency_range=(0, 5), sample_rate=300):\n",
    "    data_power = np.mean(data ** 2)\n",
    "    noise_power = data_power / (10 ** (snr / 10))\n",
    "    t = np.arange(data.shape[-1]) / sample_rate \n",
    "    noise_frequencies = np.random.uniform(frequency_range[0], frequency_range[1], size=data.shape[-1])\n",
    "    noise = np.sqrt(noise_power) * np.sin(2 * np.pi * noise_frequencies * t)\n",
    "    noisy_data = data + noise[None, ...] \n",
    "    \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_low_frequency_noise_multidim(X_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6651386549303698\n",
      "Recall: 0.39438269768747225\n",
      "F1 Score: 0.25718014433827807\n",
      "Accuracy: 0.6138374899436846\n",
      "Class 1 - Precision: 1.0, Recall: 0.004405286343612335, F1 Score: 0.008771929824561405\n",
      "Class 2 - Precision: 0.6304898648648649, Recall: 0.9946702198534311, F1 Score: 0.7717756526234169\n",
      "Class 3 - Precision: 0.9130434782608695, Recall: 0.028455284552845527, F1 Score: 0.05519053876478318\n",
      "Class 4 - Precision: 0.11702127659574468, Recall: 0.55, F1 Score: 0.1929824561403509\n",
      "Class 1 Accuracy: 0.9090909090909091\n",
      "Class 2 Accuracy: 0.6448109412711183\n",
      "Class 3 Accuracy: 0.7107803700724055\n",
      "Class 4 Accuracy: 0.9629927594529365\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_low_frequency_noise_multidim(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6713140482435181\n",
      "Recall: 0.3938880556235792\n",
      "F1 Score: 0.38120711998375334\n",
      "Accuracy: 0.6383748994368463\n",
      "Class 1 - Precision: 0.6875, Recall: 0.09691629955947137, F1 Score: 0.1698841698841699\n",
      "Class 2 - Precision: 0.6316455696202532, Recall: 0.9973351099267155, F1 Score: 0.7734435546370446\n",
      "Class 3 - Precision: 0.8955223880597015, Recall: 0.08130081300813008, F1 Score: 0.14906832298136646\n",
      "Class 4 - Precision: 0.47058823529411764, Recall: 0.4, F1 Score: 0.4324324324324324\n",
      "Class 1 Accuracy: 0.913515687851971\n",
      "Class 2 Accuracy: 0.6472244569589702\n",
      "Class 3 Accuracy: 0.7244569589702333\n",
      "Class 4 Accuracy: 0.9915526950925181\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_high_frequency_noise_multidim(data, snr, frequency_range=(0, 200), sample_rate=300):\n",
    "    data_power = np.mean(data ** 2)\n",
    "    noise_power = data_power / (10 ** (snr / 10))\n",
    "    t = np.arange(data.shape[-1]) / sample_rate \n",
    "    noise_frequencies = np.random.uniform(frequency_range[0], frequency_range[1], size=data.shape[-1])\n",
    "    noise = np.sqrt(noise_power) * np.sin(2 * np.pi * noise_frequencies * t)\n",
    "    noisy_data = data + noise[None, ...] \n",
    "    \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_high_frequency_noise_multidim(X_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4331820556353663\n",
      "Recall: 0.35526478282770835\n",
      "F1 Score: 0.26157758166473544\n",
      "Accuracy: 0.6122284794851166\n",
      "Class 1 - Precision: 0.0, Recall: 0.0, F1 Score: 0.0\n",
      "Class 2 - Precision: 0.618693134822167, Recall: 0.9966688874083944, F1 Score: 0.763460066343455\n",
      "Class 3 - Precision: 0.9473684210526315, Recall: 0.024390243902439025, F1 Score: 0.04755614266842801\n",
      "Class 4 - Precision: 0.16666666666666666, Recall: 0.4, F1 Score: 0.23529411764705882\n",
      "Class 1 Accuracy: 0.9082864038616251\n",
      "Class 2 Accuracy: 0.6271118262268705\n",
      "Class 3 Accuracy: 0.7099758648431215\n",
      "Class 4 Accuracy: 0.9790828640386162\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_high_frequency_noise_multidim(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7334765676882268\n",
      "Recall: 0.41867329852079477\n",
      "F1 Score: 0.4263217528270107\n",
      "Accuracy: 0.6468222043443282\n",
      "Class 1 - Precision: 0.7631578947368421, Recall: 0.1277533039647577, F1 Score: 0.21886792452830187\n",
      "Class 2 - Precision: 0.6363249680986814, Recall: 0.9966688874083944, F1 Score: 0.7767393561786087\n",
      "Class 3 - Precision: 0.891566265060241, Recall: 0.1002710027100271, F1 Score: 0.1802679658952497\n",
      "Class 4 - Precision: 0.6428571428571429, Recall: 0.45, F1 Score: 0.5294117647058824\n",
      "Class 1 Accuracy: 0.916733708769107\n",
      "Class 2 Accuracy: 0.6540627514078842\n",
      "Class 3 Accuracy: 0.7292839903459373\n",
      "Class 4 Accuracy: 0.9935639581657281\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
