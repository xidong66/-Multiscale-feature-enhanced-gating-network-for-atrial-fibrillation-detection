{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\database\\\\cinc2017denoise.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4500, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 4500, 32)     640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 4500, 32)     128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 4500, 32)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2250, 32)     3104        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2250, 32)     128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2250, 32)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2250, 32)     3104        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2250, 32)     1056        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2250, 32)     128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2250, 32)     128         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 2250, 32)     0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2250, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1125, 64)     6208        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 1125, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1125, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1125, 64)     12352       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1125, 64)     2112        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 1125, 64)     256         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1125, 64)     256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1125, 64)     0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1125, 64)     0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 563, 128)     24704       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 563, 128)     512         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 563, 128)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 563, 128)     49280       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 563, 128)     8320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 563, 128)     512         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 563, 128)     512         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 563, 128)     0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 563, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 128)          99072       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 128)          99072       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 128)          0           gru[0][0]                        \n",
      "                                                                 gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            516         tf.__operators__.add[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 312,356\n",
      "Trainable params: 310,948\n",
      "Non-trainable params: 1,408\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dropout, Dense,MaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x, filters, kernel_size, strides):\n",
    "    shortcut = x\n",
    "    # 主卷积路径\n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # 如果shortcut的形状与x不匹配，则调整shortcut\n",
    "    if shortcut.shape[-1] != x.shape[-1] or shortcut.shape[-2] != x.shape[-2]:\n",
    "        shortcut = Conv1D(filters, 1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "\n",
    "    # 添加跳过连接\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def resnet(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(32, 19, strides=1, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = residual_block(x, 32, 3, 2)\n",
    "    x = residual_block(x, 64, 3, 2)\n",
    "    x = residual_block(x, 128, 3, 2)\n",
    "    x1 = GRU(128, return_sequences=False)(x)\n",
    "    x2 = GRU(128, return_sequences=False)(x)\n",
    "    x=x1+x2\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "model =resnet((4500, 1), 4)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "55/55 [==============================] - 30s 325ms/step - loss: 0.4185 - accuracy: 0.5810 - val_loss: 0.4458 - val_accuracy: 0.5608\n",
      "Epoch 2/80\n",
      "55/55 [==============================] - 17s 310ms/step - loss: 0.4021 - accuracy: 0.5941 - val_loss: 0.4187 - val_accuracy: 0.5766\n",
      "Epoch 3/80\n",
      "55/55 [==============================] - 17s 304ms/step - loss: 0.3924 - accuracy: 0.6066 - val_loss: 0.4127 - val_accuracy: 0.5918\n",
      "Epoch 4/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.3671 - accuracy: 0.6454 - val_loss: 0.4302 - val_accuracy: 0.5951\n",
      "Epoch 5/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.3392 - accuracy: 0.6789 - val_loss: 0.3580 - val_accuracy: 0.6605\n",
      "Epoch 6/80\n",
      "55/55 [==============================] - 18s 318ms/step - loss: 0.3077 - accuracy: 0.7137 - val_loss: 0.3199 - val_accuracy: 0.7123\n",
      "Epoch 7/80\n",
      "55/55 [==============================] - 17s 308ms/step - loss: 0.2799 - accuracy: 0.7535 - val_loss: 0.2798 - val_accuracy: 0.7504\n",
      "Epoch 8/80\n",
      "55/55 [==============================] - 18s 318ms/step - loss: 0.2533 - accuracy: 0.7853 - val_loss: 0.2594 - val_accuracy: 0.7787\n",
      "Epoch 9/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.2400 - accuracy: 0.7968 - val_loss: 0.2649 - val_accuracy: 0.7722\n",
      "Epoch 10/80\n",
      "55/55 [==============================] - 17s 314ms/step - loss: 0.2309 - accuracy: 0.8058 - val_loss: 0.2382 - val_accuracy: 0.8071\n",
      "Epoch 11/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.2165 - accuracy: 0.8234 - val_loss: 0.2371 - val_accuracy: 0.8093\n",
      "Epoch 12/80\n",
      "55/55 [==============================] - 17s 303ms/step - loss: 0.2068 - accuracy: 0.8341 - val_loss: 0.2400 - val_accuracy: 0.7951\n",
      "Epoch 13/80\n",
      "55/55 [==============================] - 17s 310ms/step - loss: 0.1940 - accuracy: 0.8466 - val_loss: 0.2231 - val_accuracy: 0.8251\n",
      "Epoch 14/80\n",
      "55/55 [==============================] - 18s 324ms/step - loss: 0.1907 - accuracy: 0.8501 - val_loss: 0.2206 - val_accuracy: 0.8196\n",
      "Epoch 15/80\n",
      "55/55 [==============================] - 17s 314ms/step - loss: 0.1772 - accuracy: 0.8602 - val_loss: 0.2102 - val_accuracy: 0.8376\n",
      "Epoch 16/80\n",
      "55/55 [==============================] - 17s 313ms/step - loss: 0.1718 - accuracy: 0.8668 - val_loss: 0.2104 - val_accuracy: 0.8349\n",
      "Epoch 17/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1579 - accuracy: 0.8811 - val_loss: 0.2160 - val_accuracy: 0.8376\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 18/80\n",
      "55/55 [==============================] - 18s 318ms/step - loss: 0.1322 - accuracy: 0.9086 - val_loss: 0.1972 - val_accuracy: 0.8561\n",
      "Epoch 19/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1196 - accuracy: 0.9164 - val_loss: 0.1982 - val_accuracy: 0.8518\n",
      "Epoch 20/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1132 - accuracy: 0.9211 - val_loss: 0.1956 - val_accuracy: 0.8599\n",
      "Epoch 21/80\n",
      "55/55 [==============================] - 17s 305ms/step - loss: 0.1087 - accuracy: 0.9268 - val_loss: 0.1971 - val_accuracy: 0.8654\n",
      "Epoch 22/80\n",
      "55/55 [==============================] - 17s 312ms/step - loss: 0.1042 - accuracy: 0.9300 - val_loss: 0.1951 - val_accuracy: 0.8621\n",
      "Epoch 23/80\n",
      "55/55 [==============================] - 17s 308ms/step - loss: 0.1009 - accuracy: 0.9336 - val_loss: 0.1980 - val_accuracy: 0.8605\n",
      "Epoch 24/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.0970 - accuracy: 0.9366 - val_loss: 0.1987 - val_accuracy: 0.8621\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 25/80\n",
      "55/55 [==============================] - 18s 322ms/step - loss: 0.0916 - accuracy: 0.9411 - val_loss: 0.1969 - val_accuracy: 0.8632\n",
      "Epoch 26/80\n",
      "55/55 [==============================] - 17s 305ms/step - loss: 0.0903 - accuracy: 0.9430 - val_loss: 0.1967 - val_accuracy: 0.8627\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 27/80\n",
      "55/55 [==============================] - 17s 311ms/step - loss: 0.0896 - accuracy: 0.9434 - val_loss: 0.1967 - val_accuracy: 0.8627\n"
     ]
    }
   ],
   "source": [
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=256, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_low_frequency_noise_multidim(data, snr, frequency_range=(0, 5), sample_rate=300):\n",
    "    data_power = np.mean(data ** 2)\n",
    "    noise_power = data_power / (10 ** (snr / 10))\n",
    "    t = np.arange(data.shape[-1]) / sample_rate \n",
    "    noise_frequencies = np.random.uniform(frequency_range[0], frequency_range[1], size=data.shape[-1])\n",
    "    noise = np.sqrt(noise_power) * np.sin(2 * np.pi * noise_frequencies * t)\n",
    "    noisy_data = data + noise[None, ...] \n",
    "    \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_low_frequency_noise_multidim(X_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7412791302160083\n",
      "Recall: 0.6238871801044448\n",
      "F1 Score: 0.6671908737573503\n",
      "Accuracy: 0.7727272727272727\n",
      "Class 1 - Precision: 0.7337662337662337, Recall: 0.4977973568281938, F1 Score: 0.5931758530183726\n",
      "Class 2 - Precision: 0.8561961563949636, Recall: 0.8607594936708861, F1 Score: 0.8584717607973423\n",
      "Class 3 - Precision: 0.625154130702836, Recall: 0.6869918699186992, F1 Score: 0.6546158812136863\n",
      "Class 4 - Precision: 0.75, Recall: 0.45, F1 Score: 0.5625000000000001\n",
      "Class 1 Accuracy: 0.9376508447304908\n",
      "Class 2 Accuracy: 0.82864038616251\n",
      "Class 3 Accuracy: 0.7847948511665326\n",
      "Class 4 Accuracy: 0.9943684633950121\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_low_frequency_noise_multidim(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8344491618676196\n",
      "Recall: 0.7346103208711314\n",
      "F1 Score: 0.7692694180843632\n",
      "Accuracy: 0.8399034593724859\n",
      "Class 1 - Precision: 0.7805907172995781, Recall: 0.8149779735682819, F1 Score: 0.7974137931034483\n",
      "Class 2 - Precision: 0.8802318094011591, Recall: 0.9107261825449701, F1 Score: 0.8952193844138835\n",
      "Class 3 - Precision: 0.7678832116788321, Recall: 0.7127371273712737, F1 Score: 0.7392832044975404\n",
      "Class 4 - Precision: 0.9090909090909091, Recall: 0.5, F1 Score: 0.6451612903225806\n",
      "Class 1 Accuracy: 0.9621882542236525\n",
      "Class 2 Accuracy: 0.8712791633145616\n",
      "Class 3 Accuracy: 0.8507642799678198\n",
      "Class 4 Accuracy: 0.995575221238938\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_high_frequency_noise_multidim(data, snr, frequency_range=(0, 200), sample_rate=300):\n",
    "    data_power = np.mean(data ** 2)\n",
    "    noise_power = data_power / (10 ** (snr / 10))\n",
    "    t = np.arange(data.shape[-1]) / sample_rate \n",
    "    noise_frequencies = np.random.uniform(frequency_range[0], frequency_range[1], size=data.shape[-1])\n",
    "    noise = np.sqrt(noise_power) * np.sin(2 * np.pi * noise_frequencies * t)\n",
    "    noisy_data = data + noise[None, ...] \n",
    "    \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_high_frequency_noise_multidim(X_test,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7458225321406543\n",
      "Recall: 0.6529552852010689\n",
      "F1 Score: 0.6905121147410918\n",
      "Accuracy: 0.7735317779565567\n",
      "Class 1 - Precision: 0.6309523809523809, Recall: 0.4669603524229075, F1 Score: 0.5367088607594936\n",
      "Class 2 - Precision: 0.8588312541037426, Recall: 0.871419053964024, F1 Score: 0.865079365079365\n",
      "Class 3 - Precision: 0.6363636363636364, Recall: 0.6734417344173442, F1 Score: 0.654377880184332\n",
      "Class 4 - Precision: 0.8571428571428571, Recall: 0.6, F1 Score: 0.7058823529411764\n",
      "Class 1 Accuracy: 0.9263877715205149\n",
      "Class 2 Accuracy: 0.8358809332260659\n",
      "Class 3 Accuracy: 0.7888173773129525\n",
      "Class 4 Accuracy: 0.99597747385358\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_noisy = add_high_frequency_noise_multidim(X_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.839100683648159\n",
      "Recall: 0.7229181059313609\n",
      "F1 Score: 0.7657616878603206\n",
      "Accuracy: 0.8386967015285599\n",
      "Class 1 - Precision: 0.8181818181818182, Recall: 0.7533039647577092, F1 Score: 0.7844036697247706\n",
      "Class 2 - Precision: 0.8853626943005182, Recall: 0.9107261825449701, F1 Score: 0.8978653530377668\n",
      "Class 3 - Precision: 0.7437673130193906, Recall: 0.7276422764227642, F1 Score: 0.7356164383561644\n",
      "Class 4 - Precision: 0.9090909090909091, Recall: 0.5, F1 Score: 0.6451612903225806\n",
      "Class 1 Accuracy: 0.9621882542236525\n",
      "Class 2 Accuracy: 0.8748994368463395\n",
      "Class 3 Accuracy: 0.8447304907481898\n",
      "Class 4 Accuracy: 0.995575221238938\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test_noisy ,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
