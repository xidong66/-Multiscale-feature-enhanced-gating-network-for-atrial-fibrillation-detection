{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\MFEG\\\\dataprocessing\\\\cinc2017Seg.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Concatenate\n",
    "\n",
    "def ince_block(inputs, filters, strides=1):\n",
    "    x1 = Conv1D(filters, 3, strides=strides, padding='same')(inputs)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv1D(filters, 5, strides=1, padding='same')(inputs)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = Conv1D(filters, 9, strides=1, padding='same')(inputs)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    x4 = Conv1D(filters, 17, strides=1, padding='same')(inputs)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Activation('relu')(x4)\n",
    "\n",
    "    x = Concatenate()([x1, x2, x3, x4])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Reshape, Dense, Multiply\n",
    "def se_block(input_tensor, reduction_ratio=16):\n",
    "  channels = input_tensor.shape[-1]\n",
    "  x = GlobalAveragePooling1D()(input_tensor)\n",
    "  x = Reshape((1, channels))(x)\n",
    "  x = Dense(channels // reduction_ratio, activation='relu', use_bias=False)(x)\n",
    "  x = Dense(channels, activation='sigmoid', use_bias=False)(x)\n",
    "  x = Multiply()([input_tensor, x])\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, Dense, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def residual_shrinkage_block_1d(incoming, nb_blocks, out_channels, downsample=False, downsample_strides=2, activation='relu', kernel_size=31,batch_norm=True, bias=True, weights_init='variance_scaling', bias_init='zeros', regularizer='l2', weight_decay=0.0001, trainable=True, name=\"ResidualShrinkageBlock\"):\n",
    "  residual = incoming\n",
    "  in_channels = incoming.shape[-1]\n",
    "  for i in range(nb_blocks):\n",
    "    identity = residual\n",
    "    if downsample:\n",
    "      downsample_strides = 2\n",
    "    else:\n",
    "      downsample_strides = 1\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    # Thresholding\n",
    "    abs_mean = tf.reduce_mean(tf.abs(residual), axis=1, keepdims=True)\n",
    "    scales = Dense(out_channels // 4, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(abs_mean)\n",
    "    scales = BatchNormalization()(scales)\n",
    "    scales = Activation('relu')(scales)\n",
    "    scales = Dense(out_channels, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(scales)\n",
    "    scales = tf.sigmoid(scales)\n",
    "    thres = abs_mean * scales\n",
    "    residual = tf.sign(residual) * tf.maximum(tf.abs(residual) - thres, 0)\n",
    "    \n",
    "    # Downsampling and projection\n",
    "    if downsample_strides > 1:\n",
    "      identity = Conv1D(out_channels, 1, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    if in_channels != out_channels or downsample:\n",
    "      identity = Conv1D(out_channels, 1, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    residual = residual + identity\n",
    "\n",
    "  return residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add\n",
    "\n",
    "def res_block31_dilated_causal(inputs, filters, kernel_size=31, dilation_rate=2,strides=1):\n",
    "  shortcut = inputs\n",
    "  # 使用扩张卷积和因果卷积\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  \n",
    "  # 调整shortcut路径以匹配主路径的维度\n",
    "  if inputs.shape[-1] != filters:\n",
    "    shortcut = Conv1D(filters, 1, strides=strides, padding='causal')(inputs)  \n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "  \n",
    "  x = Add()([x, shortcut])\n",
    "  x = Activation('relu')(x)\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block31(inputs, filters, kernel_size=31, strides=1):\n",
    "    shortcut = inputs\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resxnet(num_classes=4):\n",
    "    input_1 = Input(shape=(4500,1))\n",
    "    x = Conv1D(64, 12, strides=2, padding='same')(input_1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ince_block(x,64)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, out_channels=32, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 32,31,2,1)\n",
    "    x = se_block(x,32)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, kernel_size=16,out_channels=64, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 64,16,2,1)\n",
    "    x = se_block(x,64)\n",
    "    x = res_block31(x, 128, kernel_size=9,strides=2)\n",
    "    x = res_block31(x, 256, kernel_size=6,strides=2)\n",
    "    x = res_block31(x, 512, kernel_size=3,strides=2)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(256, return_sequences=False)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=input_1, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4500, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 2250, 64)     832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2250, 64)     256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2250, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2250, 64)     12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2250, 64)     20544       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2250, 64)     36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2250, 64)     69696       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2250, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2250, 64)     256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2250, 64)     256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2250, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2250, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2250, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2250, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2250, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2250, 256)    0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2250, 256)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2250, 256)    1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2250, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1125, 32)     253984      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1125, 32)     128         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1125, 32)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1125, 32)     31776       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs (TFOpLambda)        (None, 1125, 32)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 1, 32)        0           tf.math.abs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 8)         264         tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 8)         32          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 8)         0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 32)        288         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 1, 32)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_1 (TFOpLambda)      (None, 1125, 32)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 1, 32)        0           tf.math.reduce_mean[0][0]        \n",
      "                                                                 tf.math.sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 1125, 32)     0           tf.math.abs_1[0][0]              \n",
      "                                                                 tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign (TFOpLambda)       (None, 1125, 32)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum (TFOpLambda)    (None, 1125, 32)     0           tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1125, 32)     8224        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 1125, 32)     0           tf.math.sign[0][0]               \n",
      "                                                                 tf.math.maximum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1125, 32)     1056        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 1125, 32)     0           tf.math.multiply_1[0][0]         \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1125, 32)     31776       tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1125, 32)     128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1125, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1125, 32)     31776       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1125, 32)     128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1125, 32)     0           batch_normalization_9[0][0]      \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1125, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 32)           0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 32)        0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1)         32          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 32)        32          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1125, 32)     0           activation_10[0][0]              \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1125, 32)     128         multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1125, 32)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 563, 64)      32832       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 563, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 563, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 563, 64)      65600       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_2 (TFOpLambda)      (None, 563, 64)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 1, 64)        0           tf.math.abs_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 16)        1040        tf.math.reduce_mean_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1, 16)        64          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1, 16)        0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 64)        1088        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_1 (TFOpLambda)  (None, 1, 64)        0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_3 (TFOpLambda)      (None, 563, 64)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 1, 64)        0           tf.math.reduce_mean_1[0][0]      \n",
      "                                                                 tf.math.sigmoid_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 563, 64)      0           tf.math.abs_3[0][0]              \n",
      "                                                                 tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign_1 (TFOpLambda)     (None, 563, 64)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum_1 (TFOpLambda)  (None, 563, 64)      0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 563, 64)      2112        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 563, 64)      0           tf.math.sign_1[0][0]             \n",
      "                                                                 tf.math.maximum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 563, 64)      4160        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 563, 64)      0           tf.math.multiply_3[0][0]         \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 563, 64)      65600       tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 563, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 563, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 563, 64)      65600       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 563, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 563, 64)      0           batch_normalization_14[0][0]     \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 563, 64)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1)         64          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 64)        64          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 563, 64)      0           activation_15[0][0]              \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 282, 128)     73856       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 282, 128)     512         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 282, 128)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 282, 128)     147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 282, 128)     8320        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 282, 128)     512         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 282, 128)     512         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 282, 128)     0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 282, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 141, 256)     196864      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 141, 256)     1024        conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 141, 256)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 141, 256)     393472      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 141, 256)     33024       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 141, 256)     1024        conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 141, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 141, 256)     0           batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 141, 256)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 71, 512)      393728      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 71, 512)      2048        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 71, 512)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 71, 512)      786944      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 71, 512)      131584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 71, 512)      2048        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 71, 512)      2048        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 71, 512)      0           batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 71, 512)      0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 71, 512)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 256)          591360      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            1028        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,509,916\n",
      "Trainable params: 3,502,700\n",
      "Non-trainable params: 7,216\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      " 6/55 [==>...........................] - ETA: 14s - loss: 5.4269 - accuracy: 0.5241WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1312s vs `on_train_batch_end` time: 0.1410s). Check your callbacks.\n",
      "55/55 [==============================] - 51s 432ms/step - loss: 3.7715 - accuracy: 0.5870 - val_loss: 2.4369 - val_accuracy: 0.5891\n",
      "Epoch 2/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 1.8382 - accuracy: 0.6990 - val_loss: 1.5298 - val_accuracy: 0.5755\n",
      "Epoch 3/80\n",
      "55/55 [==============================] - 17s 312ms/step - loss: 1.1653 - accuracy: 0.7730 - val_loss: 1.1344 - val_accuracy: 0.5755\n",
      "Epoch 4/80\n",
      "55/55 [==============================] - 17s 314ms/step - loss: 0.8199 - accuracy: 0.7974 - val_loss: 0.8133 - val_accuracy: 0.6272\n",
      "Epoch 5/80\n",
      "55/55 [==============================] - 17s 314ms/step - loss: 0.6147 - accuracy: 0.8114 - val_loss: 0.7896 - val_accuracy: 0.6065\n",
      "Epoch 6/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.4920 - accuracy: 0.8120 - val_loss: 0.5179 - val_accuracy: 0.7302\n",
      "Epoch 7/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.4086 - accuracy: 0.8202 - val_loss: 0.4408 - val_accuracy: 0.7493\n",
      "Epoch 8/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.3525 - accuracy: 0.8254 - val_loss: 0.3462 - val_accuracy: 0.8071\n",
      "Epoch 9/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.3155 - accuracy: 0.8262 - val_loss: 0.3261 - val_accuracy: 0.8082\n",
      "Epoch 10/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.2967 - accuracy: 0.8259 - val_loss: 0.3635 - val_accuracy: 0.7586\n",
      "Epoch 11/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.2781 - accuracy: 0.8269 - val_loss: 0.2899 - val_accuracy: 0.8142\n",
      "Epoch 12/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.2622 - accuracy: 0.8350 - val_loss: 0.3282 - val_accuracy: 0.7891\n",
      "Epoch 13/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.2560 - accuracy: 0.8334 - val_loss: 0.2805 - val_accuracy: 0.8005\n",
      "Epoch 14/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.2526 - accuracy: 0.8326 - val_loss: 0.2683 - val_accuracy: 0.8207\n",
      "Epoch 15/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.2408 - accuracy: 0.8385 - val_loss: 0.2907 - val_accuracy: 0.7935\n",
      "Epoch 16/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.2391 - accuracy: 0.8442 - val_loss: 0.2706 - val_accuracy: 0.8163\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 17/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.2196 - accuracy: 0.8565 - val_loss: 0.2348 - val_accuracy: 0.8305\n",
      "Epoch 18/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.2005 - accuracy: 0.8655 - val_loss: 0.2501 - val_accuracy: 0.8125\n",
      "Epoch 19/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1931 - accuracy: 0.8684 - val_loss: 0.2683 - val_accuracy: 0.7831\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 20/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1826 - accuracy: 0.8781 - val_loss: 0.2398 - val_accuracy: 0.8142\n",
      "Epoch 21/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1805 - accuracy: 0.8813 - val_loss: 0.2259 - val_accuracy: 0.8327\n",
      "Epoch 22/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1791 - accuracy: 0.8815 - val_loss: 0.2190 - val_accuracy: 0.8392\n",
      "Epoch 23/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1782 - accuracy: 0.8816 - val_loss: 0.2168 - val_accuracy: 0.8431\n",
      "Epoch 24/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1763 - accuracy: 0.8813 - val_loss: 0.2146 - val_accuracy: 0.8447\n",
      "Epoch 25/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1758 - accuracy: 0.8831 - val_loss: 0.2116 - val_accuracy: 0.8496\n",
      "Epoch 26/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1742 - accuracy: 0.8841 - val_loss: 0.2118 - val_accuracy: 0.8512\n",
      "Epoch 27/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1731 - accuracy: 0.8846 - val_loss: 0.2111 - val_accuracy: 0.8474\n",
      "Epoch 28/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1720 - accuracy: 0.8861 - val_loss: 0.2103 - val_accuracy: 0.8518\n",
      "Epoch 29/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1707 - accuracy: 0.8878 - val_loss: 0.2079 - val_accuracy: 0.8529\n",
      "Epoch 30/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1695 - accuracy: 0.8880 - val_loss: 0.2103 - val_accuracy: 0.8529\n",
      "Epoch 31/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1685 - accuracy: 0.8896 - val_loss: 0.2099 - val_accuracy: 0.8496\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 32/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1649 - accuracy: 0.8920 - val_loss: 0.2058 - val_accuracy: 0.8567\n",
      "Epoch 33/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1649 - accuracy: 0.8916 - val_loss: 0.2048 - val_accuracy: 0.8578\n",
      "Epoch 34/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1647 - accuracy: 0.8928 - val_loss: 0.2043 - val_accuracy: 0.8567\n",
      "Epoch 35/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1654 - accuracy: 0.8929 - val_loss: 0.2043 - val_accuracy: 0.8567\n",
      "Epoch 36/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1643 - accuracy: 0.8932 - val_loss: 0.2041 - val_accuracy: 0.8556\n",
      "Epoch 37/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1645 - accuracy: 0.8916 - val_loss: 0.2041 - val_accuracy: 0.8561\n",
      "Epoch 38/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1642 - accuracy: 0.8934 - val_loss: 0.2038 - val_accuracy: 0.8561\n",
      "Epoch 39/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1636 - accuracy: 0.8929 - val_loss: 0.2039 - val_accuracy: 0.8556\n",
      "Epoch 40/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1638 - accuracy: 0.8926 - val_loss: 0.2038 - val_accuracy: 0.8561\n",
      "Epoch 41/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1638 - accuracy: 0.8932 - val_loss: 0.2036 - val_accuracy: 0.8556\n",
      "Epoch 42/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1641 - accuracy: 0.8929 - val_loss: 0.2036 - val_accuracy: 0.8561\n",
      "Epoch 43/80\n",
      "55/55 [==============================] - 17s 314ms/step - loss: 0.1633 - accuracy: 0.8941 - val_loss: 0.2037 - val_accuracy: 0.8556\n",
      "Epoch 44/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1638 - accuracy: 0.8919 - val_loss: 0.2037 - val_accuracy: 0.8561\n",
      "Reduced learning rate to 1.0000001537946446e-07.\n",
      "Epoch 45/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1632 - accuracy: 0.8929 - val_loss: 0.2036 - val_accuracy: 0.8583\n",
      "Epoch 46/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1627 - accuracy: 0.8948 - val_loss: 0.2035 - val_accuracy: 0.8572\n",
      "Epoch 47/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1633 - accuracy: 0.8940 - val_loss: 0.2034 - val_accuracy: 0.8572\n",
      "Epoch 48/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1630 - accuracy: 0.8948 - val_loss: 0.2034 - val_accuracy: 0.8578\n",
      "Epoch 49/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1630 - accuracy: 0.8949 - val_loss: 0.2034 - val_accuracy: 0.8578\n",
      "Epoch 50/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1624 - accuracy: 0.8950 - val_loss: 0.2035 - val_accuracy: 0.8578\n",
      "Epoch 51/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1629 - accuracy: 0.8950 - val_loss: 0.2035 - val_accuracy: 0.8583\n",
      "Reduced learning rate to 1.000000171558213e-08.\n",
      "Epoch 52/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1625 - accuracy: 0.8941 - val_loss: 0.2034 - val_accuracy: 0.8583\n",
      "Epoch 53/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1633 - accuracy: 0.8941 - val_loss: 0.2034 - val_accuracy: 0.8578\n",
      "Epoch 54/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1632 - accuracy: 0.8940 - val_loss: 0.2034 - val_accuracy: 0.8583\n",
      "Epoch 55/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1625 - accuracy: 0.8945 - val_loss: 0.2034 - val_accuracy: 0.8583\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 56/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1629 - accuracy: 0.8939 - val_loss: 0.2034 - val_accuracy: 0.8583\n",
      "Epoch 57/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1632 - accuracy: 0.8943 - val_loss: 0.2034 - val_accuracy: 0.8583\n",
      "Epoch 58/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1630 - accuracy: 0.8936 - val_loss: 0.2035 - val_accuracy: 0.8583\n",
      "Epoch 59/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.1624 - accuracy: 0.8945 - val_loss: 0.2035 - val_accuracy: 0.8578\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 60/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1629 - accuracy: 0.8937 - val_loss: 0.2034 - val_accuracy: 0.8583\n",
      "Epoch 61/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1633 - accuracy: 0.8943 - val_loss: 0.2034 - val_accuracy: 0.8578\n",
      "Epoch 62/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1621 - accuracy: 0.8954 - val_loss: 0.2034 - val_accuracy: 0.8578\n",
      "Epoch 63/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1634 - accuracy: 0.8928 - val_loss: 0.2034 - val_accuracy: 0.8578\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 64/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1626 - accuracy: 0.8946 - val_loss: 0.2034 - val_accuracy: 0.8578\n",
      "Epoch 65/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.1629 - accuracy: 0.8936 - val_loss: 0.2034 - val_accuracy: 0.8578\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 66/80\n",
      "55/55 [==============================] - 17s 314ms/step - loss: 0.1631 - accuracy: 0.8954 - val_loss: 0.2034 - val_accuracy: 0.8578\n"
     ]
    }
   ],
   "source": [
    "model = resxnet()\n",
    "model.summary()\n",
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=256, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8534832466565996\n",
      "Recall: 0.7455822884469501\n",
      "F1 Score: 0.7788664591456178\n",
      "Accuracy: 0.8841512469831054\n",
      "Class 1 - Precision: 0.8266129032258065, Recall: 0.9030837004405287, F1 Score: 0.863157894736842\n",
      "Class 2 - Precision: 0.8880145278450363, Recall: 0.977348434377082, F1 Score: 0.9305423406279735\n",
      "Class 3 - Precision: 0.8993055555555556, Recall: 0.7018970189701897, F1 Score: 0.7884322678843226\n",
      "Class 4 - Precision: 0.8, Recall: 0.4, F1 Score: 0.5333333333333333\n",
      "Class 1 Accuracy: 0.9738535800482703\n",
      "Class 2 Accuracy: 0.911906677393403\n",
      "Class 3 Accuracy: 0.8881737731295254\n",
      "Class 4 Accuracy: 0.9943684633950121\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix2(y_test_classes, y_pred_classes, classes=['A', 'N', 'O', '~'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
