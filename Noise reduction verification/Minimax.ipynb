{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.3)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pywt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.layers import Add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import (\n",
    "  Input, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, \n",
    "  Dense, Dropout, GRU, Concatenate, LayerNormalization, MultiHeadAttention, \n",
    "  Reshape, Multiply, Softmax\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import (\n",
    "  encode_labels, check_gpu_availability, plot_loss_accuracytupian, \n",
    "  evaluate_model, plot_confusion_matrixtupian, plot_tsne, \n",
    "  plot_precision_recall_curve_multiclasstupian, plot_roc_curve_multiclasstupian, \n",
    "  AdjustLearningRateCallback, denoise2,count_labels,denoise2_iterative2,AdjustLearningRateCallback\n",
    ")\n",
    "from utils import plot_precision_recall_curve_multiclass,plot_roc_curve_multiclass2,calculate_g_mean,plot_confusion_matrix,plot_confusion_matrix2,plot_loss_accuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv1DTranspose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 可用\n"
     ]
    }
   ],
   "source": [
    "check_gpu_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "datafilename1 = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\MFEG\\\\dataprocessing\\\\cinc2017Seg.npz\"\n",
    "data1 = np.load(datafilename1, allow_pickle=True)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = data1['ecgstrain'], data1['labelstrain'], data1['ecgsval'], data1['labelsval'], data1['ecgstest'], data1['labelstest']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "def minimax_threshold(data_length):\n",
    "    if data_length >= 32:\n",
    "        threshold = 0.3936 + 0.1829 * np.log(data_length)\n",
    "    else:\n",
    "        threshold = 0.0\n",
    "    return threshold\n",
    "def denoise_with_minimax_threshold(data):\n",
    "    coeffs = pywt.wavedec(data=data, wavelet='db7', level=9)\n",
    "    cA9, cD9, cD8, cD7, cD6, cD5, cD4, cD3, cD2, cD1 = coeffs\n",
    "    sigma = np.median(np.abs(cD1)) / 0.6745\n",
    "    n = len(cD1)\n",
    "    threshold = minimax_threshold(n) * sigma\n",
    "    # 清零的系数可以是任意选择，这里我们选择 cD1 和 cD2\n",
    "    cD1.fill(0)\n",
    "    cD2.fill(0)\n",
    "    # 应用 minimax 阈值\n",
    "    for i in range(1, len(coeffs) - 2):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold, mode='soft')\n",
    "    rdata = pywt.waverec(coeffs=coeffs, wavelet='db7')\n",
    "    return rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=denoise_with_minimax_threshold(X_train)\n",
    "X_val=denoise_with_minimax_threshold(X_val)\n",
    "X_test=denoise_with_minimax_threshold(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = encode_labels(y_train)\n",
    "y_test = encode_labels(y_test)\n",
    "y_val= encode_labels(y_val)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "y_val=to_categorical(y_val, num_classes=4)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Concatenate\n",
    "\n",
    "def ince_block(inputs, filters, strides=1):\n",
    "    x1 = Conv1D(filters, 3, strides=strides, padding='same')(inputs)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv1D(filters, 5, strides=1, padding='same')(inputs)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = Conv1D(filters, 9, strides=1, padding='same')(inputs)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    x4 = Conv1D(filters, 17, strides=1, padding='same')(inputs)\n",
    "    x4 = BatchNormalization()(x4)\n",
    "    x4 = Activation('relu')(x4)\n",
    "\n",
    "    x = Concatenate()([x1, x2, x3, x4])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling1D, Reshape, Dense, Multiply\n",
    "def se_block(input_tensor, reduction_ratio=16):\n",
    "  channels = input_tensor.shape[-1]\n",
    "  x = GlobalAveragePooling1D()(input_tensor)\n",
    "  x = Reshape((1, channels))(x)\n",
    "  x = Dense(channels // reduction_ratio, activation='relu', use_bias=False)(x)\n",
    "  x = Dense(channels, activation='sigmoid', use_bias=False)(x)\n",
    "  x = Multiply()([input_tensor, x])\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Dropout, Dense, GRU\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def residual_shrinkage_block_1d(incoming, nb_blocks, out_channels, downsample=False, downsample_strides=2, activation='relu', kernel_size=31,batch_norm=True, bias=True, weights_init='variance_scaling', bias_init='zeros', regularizer='l2', weight_decay=0.0001, trainable=True, name=\"ResidualShrinkageBlock\"):\n",
    "  residual = incoming\n",
    "  in_channels = incoming.shape[-1]\n",
    "  for i in range(nb_blocks):\n",
    "    identity = residual\n",
    "    if downsample:\n",
    "      downsample_strides = 2\n",
    "    else:\n",
    "      downsample_strides = 1\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    if batch_norm:\n",
    "      residual = BatchNormalization()(residual)\n",
    "    residual = Activation(activation)(residual)\n",
    "    residual = Conv1D(out_channels, kernel_size=kernel_size, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(residual)\n",
    "    \n",
    "    # Thresholding\n",
    "    abs_mean = tf.reduce_mean(tf.abs(residual), axis=1, keepdims=True)\n",
    "    scales = Dense(out_channels // 4, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(abs_mean)\n",
    "    scales = BatchNormalization()(scales)\n",
    "    scales = Activation('relu')(scales)\n",
    "    scales = Dense(out_channels, activation='linear', kernel_regularizer=regularizer, kernel_initializer=weights_init)(scales)\n",
    "    scales = tf.sigmoid(scales)\n",
    "    thres = abs_mean * scales\n",
    "    residual = tf.sign(residual) * tf.maximum(tf.abs(residual) - thres, 0)\n",
    "    \n",
    "    # Downsampling and projection\n",
    "    if downsample_strides > 1:\n",
    "      identity = Conv1D(out_channels, 1, strides=downsample_strides, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    if in_channels != out_channels or downsample:\n",
    "      identity = Conv1D(out_channels, 1, strides=1, padding='same', kernel_initializer=weights_init, use_bias=bias, kernel_regularizer=regularizer, bias_regularizer=regularizer)(identity)\n",
    "    \n",
    "    residual = residual + identity\n",
    "\n",
    "  return residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, Activation, Add\n",
    "\n",
    "def res_block31_dilated_causal(inputs, filters, kernel_size=31, dilation_rate=2,strides=1):\n",
    "  shortcut = inputs\n",
    "  # 使用扩张卷积和因果卷积\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(inputs)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = Conv1D(filters, kernel_size, strides=1, padding='causal', dilation_rate=dilation_rate)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  \n",
    "  # 调整shortcut路径以匹配主路径的维度\n",
    "  if inputs.shape[-1] != filters:\n",
    "    shortcut = Conv1D(filters, 1, strides=strides, padding='causal')(inputs)  \n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "  \n",
    "  x = Add()([x, shortcut])\n",
    "  x = Activation('relu')(x)\n",
    "  return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block31(inputs, filters, kernel_size=31, strides=1):\n",
    "    shortcut = inputs\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=strides, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv1D(filters, kernel_size, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if strides != 1 or inputs.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, strides=strides, padding='same')(inputs)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resxnet(num_classes=4):\n",
    "    input_1 = Input(shape=(4500,1))\n",
    "    x = Conv1D(64, 12, strides=2, padding='same')(input_1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = ince_block(x,64)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, out_channels=32, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 32,31,2,1)\n",
    "    x = se_block(x,32)\n",
    "    x = residual_shrinkage_block_1d(x, nb_blocks=1, kernel_size=16,out_channels=64, downsample=True)\n",
    "    x = res_block31_dilated_causal(x, 64,16,2,1)\n",
    "    x = se_block(x,64)\n",
    "    x = res_block31(x, 128, kernel_size=9,strides=2)\n",
    "    x = res_block31(x, 256, kernel_size=6,strides=2)\n",
    "    x = res_block31(x, 512, kernel_size=3,strides=2)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(256, return_sequences=False)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=input_1, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4500, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 2250, 64)     832         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2250, 64)     256         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2250, 64)     0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 2250, 64)     12352       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 2250, 64)     20544       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2250, 64)     36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 2250, 64)     69696       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2250, 64)     256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2250, 64)     256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2250, 64)     256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2250, 64)     256         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2250, 64)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 2250, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 2250, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 2250, 64)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2250, 256)    0           activation_1[0][0]               \n",
      "                                                                 activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 2250, 256)    0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2250, 256)    1024        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2250, 256)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1125, 32)     253984      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1125, 32)     128         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1125, 32)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1125, 32)     31776       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs (TFOpLambda)        (None, 1125, 32)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 1, 32)        0           tf.math.abs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 8)         264         tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1, 8)         32          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1, 8)         0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 32)        288         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 1, 32)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_1 (TFOpLambda)      (None, 1125, 32)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 1, 32)        0           tf.math.reduce_mean[0][0]        \n",
      "                                                                 tf.math.sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 1125, 32)     0           tf.math.abs_1[0][0]              \n",
      "                                                                 tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign (TFOpLambda)       (None, 1125, 32)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum (TFOpLambda)    (None, 1125, 32)     0           tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1125, 32)     8224        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 1125, 32)     0           tf.math.sign[0][0]               \n",
      "                                                                 tf.math.maximum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1125, 32)     1056        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 1125, 32)     0           tf.math.multiply_1[0][0]         \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1125, 32)     31776       tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 1125, 32)     128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1125, 32)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1125, 32)     31776       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 1125, 32)     128         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 1125, 32)     0           batch_normalization_9[0][0]      \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1125, 32)     0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 32)           0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 32)        0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 1)         32          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1, 32)        32          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 1125, 32)     0           activation_10[0][0]              \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1125, 32)     128         multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1125, 32)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 563, 64)      32832       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 563, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 563, 64)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 563, 64)      65600       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_2 (TFOpLambda)      (None, 563, 64)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 1, 64)        0           tf.math.abs_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1, 16)        1040        tf.math.reduce_mean_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1, 16)        64          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1, 16)        0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1, 64)        1088        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_1 (TFOpLambda)  (None, 1, 64)        0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_3 (TFOpLambda)      (None, 563, 64)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 1, 64)        0           tf.math.reduce_mean_1[0][0]      \n",
      "                                                                 tf.math.sigmoid_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_1 (TFOpLambda) (None, 563, 64)      0           tf.math.abs_3[0][0]              \n",
      "                                                                 tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sign_1 (TFOpLambda)     (None, 563, 64)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum_1 (TFOpLambda)  (None, 563, 64)      0           tf.math.subtract_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 563, 64)      2112        multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) (None, 563, 64)      0           tf.math.sign_1[0][0]             \n",
      "                                                                 tf.math.maximum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 563, 64)      4160        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 563, 64)      0           tf.math.multiply_3[0][0]         \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 563, 64)      65600       tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 563, 64)      256         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 563, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 563, 64)      65600       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 563, 64)      256         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 563, 64)      0           batch_normalization_14[0][0]     \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 563, 64)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 64)        0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1, 1)         64          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 64)        64          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 563, 64)      0           activation_15[0][0]              \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 282, 128)     73856       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 282, 128)     512         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 282, 128)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 282, 128)     147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 282, 128)     8320        multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 282, 128)     512         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 282, 128)     512         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 282, 128)     0           batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 282, 128)     0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 141, 256)     196864      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 141, 256)     1024        conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 141, 256)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 141, 256)     393472      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 141, 256)     33024       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 141, 256)     1024        conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 141, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 141, 256)     0           batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 141, 256)     0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 71, 512)      393728      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 71, 512)      2048        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 71, 512)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 71, 512)      786944      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 71, 512)      131584      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 71, 512)      2048        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 71, 512)      2048        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 71, 512)      0           batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 71, 512)      0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 71, 512)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (None, 256)          591360      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            1028        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,509,916\n",
      "Trainable params: 3,502,700\n",
      "Non-trainable params: 7,216\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/80\n",
      " 6/55 [==>...........................] - ETA: 14s - loss: 5.3850 - accuracy: 0.5352WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1279s vs `on_train_batch_end` time: 0.1431s). Check your callbacks.\n",
      "55/55 [==============================] - 45s 425ms/step - loss: 3.7241 - accuracy: 0.5850 - val_loss: 2.4194 - val_accuracy: 0.5793\n",
      "Epoch 2/80\n",
      "55/55 [==============================] - 17s 312ms/step - loss: 1.8265 - accuracy: 0.7097 - val_loss: 1.5461 - val_accuracy: 0.5733\n",
      "Epoch 3/80\n",
      "55/55 [==============================] - 17s 314ms/step - loss: 1.1718 - accuracy: 0.7684 - val_loss: 1.0928 - val_accuracy: 0.5995\n",
      "Epoch 4/80\n",
      "55/55 [==============================] - 17s 315ms/step - loss: 0.8265 - accuracy: 0.7961 - val_loss: 0.9204 - val_accuracy: 0.5896\n",
      "Epoch 5/80\n",
      "55/55 [==============================] - 17s 316ms/step - loss: 0.6239 - accuracy: 0.8057 - val_loss: 0.6502 - val_accuracy: 0.6948\n",
      "Epoch 6/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.5008 - accuracy: 0.8088 - val_loss: 0.5958 - val_accuracy: 0.6796\n",
      "Epoch 7/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.4205 - accuracy: 0.8137 - val_loss: 0.4432 - val_accuracy: 0.7668\n",
      "Epoch 8/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.3579 - accuracy: 0.8229 - val_loss: 0.3471 - val_accuracy: 0.8213\n",
      "Epoch 9/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.3218 - accuracy: 0.8246 - val_loss: 0.4175 - val_accuracy: 0.6627\n",
      "Epoch 10/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.2958 - accuracy: 0.8286 - val_loss: 0.3117 - val_accuracy: 0.8049\n",
      "Epoch 11/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.2737 - accuracy: 0.8323 - val_loss: 0.3085 - val_accuracy: 0.8098\n",
      "Epoch 12/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.2628 - accuracy: 0.8342 - val_loss: 0.3549 - val_accuracy: 0.7215\n",
      "Epoch 13/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.2543 - accuracy: 0.8316 - val_loss: 0.2890 - val_accuracy: 0.7891\n",
      "Epoch 14/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.2486 - accuracy: 0.8356 - val_loss: 0.2513 - val_accuracy: 0.8245\n",
      "Epoch 15/80\n",
      "55/55 [==============================] - 18s 319ms/step - loss: 0.2397 - accuracy: 0.8401 - val_loss: 0.3060 - val_accuracy: 0.7689\n",
      "Epoch 16/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.2370 - accuracy: 0.8395 - val_loss: 0.2702 - val_accuracy: 0.8054\n",
      "Reduced learning rate to 0.00010000000474974513.\n",
      "Epoch 17/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.2110 - accuracy: 0.8596 - val_loss: 0.2385 - val_accuracy: 0.8294\n",
      "Epoch 18/80\n",
      "55/55 [==============================] - 18s 318ms/step - loss: 0.1963 - accuracy: 0.8694 - val_loss: 0.2489 - val_accuracy: 0.8076\n",
      "Epoch 19/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1891 - accuracy: 0.8711 - val_loss: 0.2509 - val_accuracy: 0.8054\n",
      "Reduced learning rate to 1.0000000656873453e-05.\n",
      "Epoch 20/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1817 - accuracy: 0.8767 - val_loss: 0.2320 - val_accuracy: 0.8332\n",
      "Epoch 21/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1784 - accuracy: 0.8802 - val_loss: 0.2232 - val_accuracy: 0.8387\n",
      "Epoch 22/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1765 - accuracy: 0.8807 - val_loss: 0.2174 - val_accuracy: 0.8414\n",
      "Epoch 23/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1755 - accuracy: 0.8822 - val_loss: 0.2163 - val_accuracy: 0.8392\n",
      "Epoch 24/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1740 - accuracy: 0.8825 - val_loss: 0.2129 - val_accuracy: 0.8376\n",
      "Epoch 25/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1735 - accuracy: 0.8828 - val_loss: 0.2126 - val_accuracy: 0.8398\n",
      "Epoch 26/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1727 - accuracy: 0.8827 - val_loss: 0.2098 - val_accuracy: 0.8409\n",
      "Epoch 27/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1708 - accuracy: 0.8854 - val_loss: 0.2103 - val_accuracy: 0.8392\n",
      "Epoch 28/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1706 - accuracy: 0.8843 - val_loss: 0.2109 - val_accuracy: 0.8403\n",
      "Reduced learning rate to 1.0000001111620804e-06.\n",
      "Epoch 29/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1682 - accuracy: 0.8858 - val_loss: 0.2073 - val_accuracy: 0.8431\n",
      "Epoch 30/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1675 - accuracy: 0.8871 - val_loss: 0.2060 - val_accuracy: 0.8447\n",
      "Epoch 31/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1669 - accuracy: 0.8869 - val_loss: 0.2054 - val_accuracy: 0.8463\n",
      "Epoch 32/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1678 - accuracy: 0.8869 - val_loss: 0.2051 - val_accuracy: 0.8458\n",
      "Epoch 33/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1677 - accuracy: 0.8882 - val_loss: 0.2048 - val_accuracy: 0.8458\n",
      "Epoch 34/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1674 - accuracy: 0.8871 - val_loss: 0.2048 - val_accuracy: 0.8458\n",
      "Epoch 35/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1670 - accuracy: 0.8874 - val_loss: 0.2049 - val_accuracy: 0.8463\n",
      "Epoch 36/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1665 - accuracy: 0.8874 - val_loss: 0.2047 - val_accuracy: 0.8452\n",
      "Epoch 37/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1666 - accuracy: 0.8884 - val_loss: 0.2047 - val_accuracy: 0.8452\n",
      "Epoch 38/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1666 - accuracy: 0.8875 - val_loss: 0.2046 - val_accuracy: 0.8452\n",
      "Epoch 39/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1664 - accuracy: 0.8874 - val_loss: 0.2046 - val_accuracy: 0.8458\n",
      "Epoch 40/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1664 - accuracy: 0.8876 - val_loss: 0.2046 - val_accuracy: 0.8447\n",
      "Epoch 41/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1664 - accuracy: 0.8879 - val_loss: 0.2044 - val_accuracy: 0.8474\n",
      "Epoch 42/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1668 - accuracy: 0.8873 - val_loss: 0.2042 - val_accuracy: 0.8447\n",
      "Epoch 43/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1661 - accuracy: 0.8888 - val_loss: 0.2042 - val_accuracy: 0.8441\n",
      "Epoch 44/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1656 - accuracy: 0.8881 - val_loss: 0.2043 - val_accuracy: 0.8463\n",
      "Reduced learning rate to 1.0000001537946446e-07.\n",
      "Epoch 45/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1657 - accuracy: 0.8895 - val_loss: 0.2042 - val_accuracy: 0.8452\n",
      "Epoch 46/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1658 - accuracy: 0.8881 - val_loss: 0.2042 - val_accuracy: 0.8447\n",
      "Epoch 47/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1655 - accuracy: 0.8876 - val_loss: 0.2042 - val_accuracy: 0.8441\n",
      "Epoch 48/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1649 - accuracy: 0.8894 - val_loss: 0.2042 - val_accuracy: 0.8441\n",
      "Epoch 49/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1655 - accuracy: 0.8886 - val_loss: 0.2042 - val_accuracy: 0.8441\n",
      "Epoch 50/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1655 - accuracy: 0.8900 - val_loss: 0.2041 - val_accuracy: 0.8441\n",
      "Epoch 51/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1661 - accuracy: 0.8888 - val_loss: 0.2041 - val_accuracy: 0.8447\n",
      "Epoch 52/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1651 - accuracy: 0.8894 - val_loss: 0.2041 - val_accuracy: 0.8447\n",
      "Epoch 53/80\n",
      "55/55 [==============================] - 18s 319ms/step - loss: 0.1655 - accuracy: 0.8876 - val_loss: 0.2041 - val_accuracy: 0.8441\n",
      "Reduced learning rate to 1.000000171558213e-08.\n",
      "Epoch 54/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1650 - accuracy: 0.8905 - val_loss: 0.2041 - val_accuracy: 0.8447\n",
      "Epoch 55/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1658 - accuracy: 0.8888 - val_loss: 0.2041 - val_accuracy: 0.8447\n",
      "Epoch 56/80\n",
      "55/55 [==============================] - 17s 317ms/step - loss: 0.1653 - accuracy: 0.8890 - val_loss: 0.2041 - val_accuracy: 0.8447\n",
      "Epoch 57/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1652 - accuracy: 0.8884 - val_loss: 0.2041 - val_accuracy: 0.8441\n",
      "Epoch 58/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1657 - accuracy: 0.8876 - val_loss: 0.2041 - val_accuracy: 0.8447\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 59/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1650 - accuracy: 0.8886 - val_loss: 0.2041 - val_accuracy: 0.8447\n",
      "Epoch 60/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1653 - accuracy: 0.8887 - val_loss: 0.2041 - val_accuracy: 0.8447\n",
      "Reduced learning rate to 1e-08.\n",
      "Epoch 61/80\n",
      "55/55 [==============================] - 17s 318ms/step - loss: 0.1658 - accuracy: 0.8887 - val_loss: 0.2041 - val_accuracy: 0.8447\n"
     ]
    }
   ],
   "source": [
    "model = resxnet()\n",
    "model.summary()\n",
    "callback = AdjustLearningRateCallback(factor=0.1, patience=2, min_lr=1e-8)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, batch_size=256, epochs=80, validation_data=(X_val, y_val), callbacks=[callback,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(model.predict(X_test), axis=-1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9076050908389895\n",
      "Recall: 0.7906455573557077\n",
      "F1 Score: 0.8322884225335401\n",
      "Accuracy: 0.8869670152855994\n",
      "Class 1 - Precision: 0.8291666666666667, Recall: 0.8766519823788547, F1 Score: 0.8522483940042827\n",
      "Class 2 - Precision: 0.8842925659472423, Recall: 0.9826782145236509, F1 Score: 0.9308930261912276\n",
      "Class 3 - Precision: 0.9169611307420494, Recall: 0.7032520325203252, F1 Score: 0.7960122699386503\n",
      "Class 4 - Precision: 1.0, Recall: 0.6, F1 Score: 0.7499999999999999\n",
      "Class 1 Accuracy: 0.9722445695897023\n",
      "Class 2 Accuracy: 0.911906677393403\n",
      "Class 3 Accuracy: 0.8930008045052292\n",
      "Class 4 Accuracy: 0.996781979082864\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix2(y_test_classes, y_pred_classes, classes=['A', 'N', 'O', '~'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
